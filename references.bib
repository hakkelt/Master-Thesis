
@article{fessler_nonuniform_2003,
	title = {Nonuniform fast Fourier transforms using min-max interpolation},
	volume = {51},
	issn = {1941-0476},
	doi = {10.1109/TSP.2002.807005},
	abstract = {The fast Fourier transform ({FFT}) is used widely in signal processing for efficient computation of the {FT} of finite-length signals over a set of uniformly spaced frequency locations. However, in many applications, one requires nonuniform sampling in the frequency domain, i.e., a nonuniform {FT}. Several papers have described fast approximations for the nonuniform {FT} based on interpolating an oversampled {FFT}. This paper presents an interpolation method for the nonuniform {FT} that is optimal in the min-max sense of minimizing the worst-case approximation error over all signals of unit norm. The proposed method easily generalizes to multidimensional signals. Numerical results show that the min-max approach provides substantially lower approximation errors than conventional interpolation methods. The min-max criterion is also useful for optimizing the parameters of interpolation kernels such as the Kaiser-Bessel function.},
	pages = {560--574},
	number = {2},
	journaltitle = {{IEEE} Transactions on Signal Processing},
	author = {Fessler, J.A. and Sutton, B.P.},
	date = {2003-02},
	note = {Conference Name: {IEEE} Transactions on Signal Processing},
	keywords = {Approximation error, {FFT}, Fast Fourier transforms, Frequency domain analysis, Image reconstruction, Interpolation, Iterative methods, Kaiser-Bessel function, Magnetic resonance imaging, Multidimensional signal processing, Multidimensional systems, Nonuniform sampling, fast Fourier transforms, frequency domain, frequency-domain analysis, interpolation, min-max interpolation, minimax techniques, multidimensional signal processing, multidimensional signals, nonuniform {FT}, nonuniform fast Fourier transforms, nonuniform sampling, signal processing, signal sampling, worst-case approximation error}
}

@online{noauthor_sigpy_nodate,
	title = {{SigPy} ‚Äî sigpy 0.1.16 documentation},
	url = {https://sigpy.readthedocs.io/en/latest/},
	urldate = {2020-05-25}
}

@online{noauthor_novel_nodate,
	title = {Novel Algorithms based on Majorization Minimization for Nonnegative Matrix Factorization},
	url = {https://www.groundai.com/project/novel-algorithms-based-on-majorization-minimization-for-nonnegative-matrix-factorization/1},
	abstract = {Matrix decomposition is ubiquitous and has applications in various fields like speech processing, data mining and image processing to name a few. Under matrix decomposition, nonnegative matrix factorization is used to decompose a nonnegative matrix into a product of two nonnegative matrices which gives some meaningful interpretation of the data. Thus, nonnegative matrix factorization has an edge over the other decomposition techniques. In this paper, we propose two novel iterative algorithms based on Majorization Minimization ({MM})-in which we formulate a novel upper bound and minimize it to get a closed form solution at every iteration. Since the algorithms are based ‚Ä¶},
	titleaddon = {{GroundAI}},
	urldate = {2020-05-25},
	langid = {english},
	note = {Library Catalog: www.groundai.com}
}

@article{daubechies_iteratively_2010,
	title = {Iteratively reweighted least squares minimization for sparse recovery},
	volume = {63},
	rights = {Copyright ¬© 2009 Wiley Periodicals, Inc.},
	issn = {1097-0312},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.20303},
	doi = {10.1002/cpa.20303},
	abstract = {Under certain conditions (known as the restricted isometry property, or {RIP}) on the m √ó N matrix Œ¶ (where m {\textless} N), vectors x ‚àà ‚ÑùN that are sparse (i.e., have most of their entries equal to 0) can be recovered exactly from y := Œ¶x even though Œ¶‚àí1(y) is typically an (N ‚àí m)‚Äîdimensional hyperplane; in addition, x is then equal to the element in Œ¶‚àí1(y) of minimal ùìÅ1-norm. This minimal element can be identified via linear programming algorithms. We study an alternative method of determining x, as the limit of an iteratively reweighted least squares ({IRLS}) algorithm. The main step of this {IRLS} finds, for a given weight vector w, the element in Œ¶‚àí1(y) with smallest ùìÅ2(w)-norm. If x(n) is the solution at iteration step n, then the new weight w(n) is defined by w := [{\textbar}x{\textbar}2 + Œµ]‚àí1/2, i = 1, ‚Ä¶, N, for a decreasing sequence of adaptively defined Œµn; this updated weight is then used to obtain x(n + 1) and the process is repeated. We prove that when Œ¶ satisfies the {RIP} conditions, the sequence x(n) converges for all y, regardless of whether Œ¶‚àí1(y) contains a sparse vector. If there is a sparse vector in Œ¶‚àí1(y), then the limit is this sparse vector, and when x(n) is sufficiently close to the limit, the remaining steps of the algorithm converge exponentially fast (linear convergence in the terminology of numerical optimization). The same algorithm with the ‚Äúheavier‚Äù weight w = [{\textbar}x{\textbar}2 + Œµ]‚àí1+œÑ/2, i = 1, ‚Ä¶, N, where 0 {\textless} œÑ {\textless} 1, can recover sparse solutions as well; more importantly, we show its local convergence is superlinear and approaches a quadratic rate for œÑ approaching 0. ¬© 2009 Wiley Periodicals, Inc.},
	pages = {1--38},
	number = {1},
	journaltitle = {Communications on Pure and Applied Mathematics},
	author = {Daubechies, Ingrid and {DeVore}, Ronald and Fornasier, Massimo and G√ºnt√ºrk, C. SiÃánan},
	urldate = {2020-05-25},
	date = {2010},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpa.20303}
}

@inproceedings{chartrand_iteratively_2008,
	title = {Iteratively reweighted algorithms for compressive sensing},
	doi = {10.1109/ICASSP.2008.4518498},
	abstract = {The theory of compressive sensing has shown that sparse signals can be reconstructed exactly from many fewer measurements than traditionally believed necessary. In [1], it was shown empirically that using lscrp minimization with p {\textless} 1 can do so with fewer measurements than with p = 1. In this paper we consider the use of iteratively reweighted algorithms for computing local minima of the nonconvex problem. In particular, a particular regularization strategy is found to greatly improve the ability of a reweighted least-squares algorithm to recover sparse signals, with exact recovery being observed for signals that are much less sparse than required by an unregularized version (such as {FOCUSS}, [2]). Improvements are also observed for the reweighted-lscr1 approach of [3].},
	eventtitle = {2008 {IEEE} International Conference on Acoustics, Speech and Signal Processing},
	pages = {3869--3872},
	booktitle = {2008 {IEEE} International Conference on Acoustics, Speech and Signal Processing},
	author = {Chartrand, Rick and Wotao Yin},
	date = {2008-03},
	note = {{ISSN}: 2379-190X},
	keywords = {Biomedical imaging, Compressive sensing, Focusing, Image coding, Image reconstruction, Iterative algorithms, Laboratories, Least squares methods, Pursuit algorithms, Signal reconstruction, Size measurement, compressive sensing theory, iterative methods, iteratively reweighted algorithm, iteratively reweighted least squares, least squares approximations, nonconvex optimization, reweighted least-squares algorithm, signal reconstruction, ‚Ñì1 minimization}
}

@article{gorodnitsky_neuromagnetic_1995,
	title = {Neuromagnetic source imaging with {FOCUSS}: a recursive weighted minimum norm algorithm},
	volume = {95},
	issn = {0013-4694},
	url = {http://www.sciencedirect.com/science/article/pii/001346949500107A},
	doi = {10.1016/0013-4694(95)00107-A},
	shorttitle = {Neuromagnetic source imaging with {FOCUSS}},
	abstract = {The paper describes a new algorithm for tomographic source reconstruction in neural electromagnetic inverse problems. Termed {FOCUSS} ({FOCal} Underdetermined System Solution), this algorithm combines the desired features of the two major approaches to electromagnetic inverse procedures. Like multiple current dipole modeling methods, {FOCUSS} produces high resolution solutions appropriate for the highly localized sources often encountered in electromagnetic imaging. Like linear estimation methods, {FOCUSS} allows current sources to assume arbitrary shapes and it preserves the generality and ease of application characteristic of this group of methods. It stands apart from standard signal processing techniques because, as an initialization-dependent algorithm, it accommodates the non-unique set of feasible solutions that arise from the neuroelectric source constraints. {FOCUSS} is based on recursive, weighted norm minimization. The consequence of the repeated weighting procedure is, in effect, to concentrate the solution in the minimal active regions that are essential for accurately reproducing the measurements. The {FOCUSS} algorithm is introduced and its properties are illustrated in the context of a number of simulations, first using exact measurements in 2- and 3-D problems, and then in the presence of noise and modeling errors. The results suggest that {FOCUSS} is a powerful algorithm with considerable utility for tomographic current estimation.},
	pages = {231--251},
	number = {4},
	journaltitle = {Electroencephalography and Clinical Neurophysiology},
	shortjournal = {Electroencephalography and Clinical Neurophysiology},
	author = {Gorodnitsky, Irina F. and George, John S. and Rao, Bhaskar D.},
	urldate = {2020-05-25},
	date = {1995-10-01},
	langid = {english},
	keywords = {{EEG}/{MEG}, Neuromagnetic source localization, Recursive weighted minimum norm algorithm}
}

@article{recht_guaranteed_2010,
	title = {Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization},
	volume = {52},
	issn = {0036-1445},
	url = {https://epubs.siam.org/doi/abs/10.1137/070697835},
	doi = {10.1137/070697835},
	abstract = {The affine rank minimization problem consists of finding a matrix of minimum rank that satisfies a given system of linear equality constraints. Such problems have appeared in the literature of a diverse set of fields including system identification and control, Euclidean embedding, and collaborative filtering. Although specific instances can often be solved with specialized algorithms, the general affine rank minimization problem is {NP}-hard because it contains vector cardinality minimization as a special case. In this paper, we show that if a certain restricted isometry property holds for the linear transformation defining the constraints, the minimum-rank solution can be recovered by solving a convex optimization problem, namely, the minimization of the nuclear norm over the given affine space. We present several random ensembles of equations where the restricted isometry property holds with overwhelming probability, provided the codimension of the subspace is sufficiently large. The techniques used in our analysis have strong parallels in the compressed sensing framework. We discuss how affine rank minimization generalizes this preexisting concept and outline a dictionary relating concepts from cardinality minimization to those of rank minimization. We also discuss several algorithmic approaches to minimizing the nuclear norm and illustrate our results with numerical examples.},
	pages = {471--501},
	number = {3},
	journaltitle = {{SIAM} Review},
	shortjournal = {{SIAM} Rev.},
	author = {Recht, Benjamin and Fazel, Maryam and Parrilo, Pablo A.},
	urldate = {2020-05-25},
	date = {2010-01-01},
	note = {Publisher: Society for Industrial and Applied Mathematics}
}

@article{burer_nonlinear_2003,
	title = {A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization},
	volume = {95},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-002-0352-8},
	doi = {10.1007/s10107-002-0352-8},
	abstract = {In this paper, we present a nonlinear programming algorithm for solving semidefinite programs ({SDPs}) in standard form. The algorithm's distinguishing feature is a change of variables that replaces the symmetric, positive semidefinite variable X of the {SDP} with a rectangular variable R according to the factorization X={RRT}. The rank of the factorization, i.e., the number of columns of R, is chosen minimally so as to enhance computational speed while maintaining equivalence with the {SDP}. Fundamental results concerning the convergence of the algorithm are derived, and encouraging computational results on some large-scale test problems are also presented.},
	pages = {329--357},
	number = {2},
	journaltitle = {Mathematical Programming},
	shortjournal = {Math. Program., Ser. B},
	author = {Burer, Samuel and Monteiro, Renato D.C.},
	urldate = {2020-05-25},
	date = {2003-02-01},
	langid = {english}
}

@online{bezanson_why_2012,
	title = {Why We Created Julia},
	url = {https://julialang.org/blog/2012/02/why-we-created-julia/},
	abstract = {Official website for the Julia programming language},
	titleaddon = {The Julia Language},
	author = {Bezanson, Jeff and Karpinski, Stephan and Shah, Viral and Edelman, Alan},
	urldate = {2020-05-25},
	date = {2012-02-14},
	langid = {english},
	note = {Library Catalog: julialang.org}
}

@software{noauthor_kul-forbesabstractoperatorsjl_2020,
	title = {kul-forbes/{AbstractOperators}.jl},
	url = {https://github.com/kul-forbes/AbstractOperators.jl},
	abstract = {Abstract operators for large scale optimization in Julia},
	publisher = {{KUL} {ForBES}},
	urldate = {2020-05-25},
	date = {2020-04-05},
	note = {original-date: 2017-05-26T11:58:10Z},
	keywords = {automatic-differentiation, back-propagation, derivatives, julia-language, large-scale, optimization}
}

@software{noauthor_juliasmoothoptimizerslinearoperatorsjl_2020,
	title = {{JuliaSmoothOptimizers}/{LinearOperators}.jl},
	rights = {{MPL}-2.0},
	url = {https://github.com/JuliaSmoothOptimizers/LinearOperators.jl},
	abstract = {Linear Operators for Julia. Contribute to {JuliaSmoothOptimizers}/{LinearOperators}.jl development by creating an account on {GitHub}.},
	publisher = {{JuliaSmoothOptimizers}},
	urldate = {2020-05-25},
	date = {2020-04-24},
	note = {original-date: 2014-05-24T18:01:00Z},
	keywords = {julia, julia-language, linear-maps, linear-operators, matrices, preconditioner}
}

@software{jutho_jutholinearmapsjl_2020,
	title = {Jutho/{LinearMaps}.jl},
	url = {https://github.com/Jutho/LinearMaps.jl},
	abstract = {A Julia package for defining and working with linear maps, also known as linear transformations or linear operators acting on vectors. The only requirement for a {LinearMap} is that it can act on a v...},
	author = {Jutho},
	urldate = {2020-05-25},
	date = {2020-05-09},
	note = {original-date: 2014-06-15T12:24:03Z}
}

@online{noauthor_k-space_nodate,
	title = {k-space: {FOV}},
	url = {http://mriquestions.com/field-of-view-fov.html},
	shorttitle = {k-space},
	abstract = {How does k-space relate to field-of-view ({FOV}) and pixel width?},
	titleaddon = {Questions and Answers in {MRI}},
	urldate = {2020-05-13},
	langid = {english}
}

@article{van_der_vorst_bi-cgstab_1992,
	title = {Bi-{CGSTAB}: A Fast and Smoothly Converging Variant of Bi-{CG} for the Solution of Nonsymmetric Linear Systems},
	volume = {13},
	issn = {0196-5204},
	url = {https://epubs.siam.org/doi/10.1137/0913035},
	doi = {10.1137/0913035},
	shorttitle = {Bi-{CGSTAB}},
	abstract = {Recently the Conjugate Gradients-Squared ({CG}-S) method has been proposed as an attractive variant of the Bi-Conjugate Gradients (Bi-{CG}) method. However, it has been observed that {CG}-S may lead to a rather irregular convergence behaviour, so that in some cases rounding errors can even result in severe cancellation effects in the solution. In this paper, another variant of Bi-{CG} is proposed which does not seem to suffer from these negative effects. Numerical experiments indicate also that the new variant, named Bi-{CGSTAB}, is often much more efficient than {CG}-S.},
	pages = {631--644},
	number = {2},
	journaltitle = {{SIAM} Journal on Scientific and Statistical Computing},
	shortjournal = {{SIAM} J. Sci. and Stat. Comput.},
	author = {van der Vorst, H. A.},
	urldate = {2020-05-23},
	date = {1992-03-01},
	note = {Publisher: Society for Industrial and Applied Mathematics}
}

@inproceedings{fazel_log-det_2003,
	title = {Log-det heuristic for matrix rank minimization with applications to Hankel and Euclidean distance matrices},
	volume = {3},
	doi = {10.1109/ACC.2003.1243393},
	abstract = {We present a heuristic for minimizing the rank of a positive semidefinite matrix over a convex set. We use the logarithm of the determinant as a smooth approximation for rank, and locally minimize this function to obtain a sequence of trace minimization problems. We then present a lemma that relates the rank of any general matrix to that of a corresponding positive semidefinite one. Using this, we readily extend the proposed heuristic to handle general matrices. We examine the vector case as a special case, where the heuristic reduces to an iterative l/sub 1/-norm minimization technique. As practical applications of the rank minimization problem and our heuristic, we consider two examples: minimum-order system realization with time-domain constraints, and finding lowest-dimension embedding of points in a Euclidean space from noisy distance data.},
	eventtitle = {Proceedings of the 2003 American Control Conference, 2003.},
	pages = {2156--2162 vol.3},
	booktitle = {Proceedings of the 2003 American Control Conference, 2003.},
	author = {Fazel, M. and Hindi, H. and Boyd, S.P.},
	date = {2003-06},
	note = {{ISSN}: 0743-1619},
	keywords = {Computational geometry, Constraint optimization, Control systems, Electronic mail, Euclidean distance, Euclidean distance matrices, Euclidean space, Hankel distance matrices, Hankel matrices, Signal processing, Statistics, System identification, Time domain analysis, Yttrium, convex programming, convex set, determinants, general matrix, iterative methods, iterative minimization technique, lemma, local minimization, log det heuristics, lowest dimension embedding points, matrix rank minimization, minimisation, minimum-order system realization, noisy distance data, positive semidefinite matrix, smooth rank approximation, time domain constraints, time-domain analysis, trace minimization problems, vector case}
}

@article{otazo_low-rank_2015,
	title = {Low-rank plus sparse matrix decomposition for accelerated dynamic {MRI} with separation of background and dynamic components},
	volume = {73},
	rights = {¬© 2014 Wiley Periodicals, Inc.},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.25240},
	doi = {10.1002/mrm.25240},
	abstract = {Purpose To apply the low-rank plus sparse (L+S) matrix decomposition model to reconstruct undersampled dynamic {MRI} as a superposition of background and dynamic components in various problems of clinical interest. Theory and Methods The L+S model is natural to represent dynamic {MRI} data. Incoherence between k-t space (acquisition) and the singular vectors of L and the sparse domain of S is required to reconstruct undersampled data. Incoherence between L and S is required for robust separation of background and dynamic components. Multicoil L+S reconstruction is formulated using a convex optimization approach, where the nuclear norm is used to enforce low rank in L and the l1 norm is used to enforce sparsity in S. Feasibility of the L+S reconstruction was tested in several dynamic {MRI} experiments with true acceleration, including cardiac perfusion, cardiac cine, time-resolved angiography, and abdominal and breast perfusion using Cartesian and radial sampling. Results The L+S model increased compressibility of dynamic {MRI} data and thus enabled high-acceleration factors. The inherent background separation improved background suppression performance compared to conventional data subtraction, which is sensitive to motion. Conclusion The high acceleration and background separation enabled by L+S promises to enhance spatial and temporal resolution and to enable background suppression without the need of subtraction or modeling. Magn Reson Med 73:1125‚Äì1136, 2015. ¬© 2014 Wiley Periodicals, Inc.},
	pages = {1125--1136},
	number = {3},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Otazo, Ricardo and Cand√®s, Emmanuel and Sodickson, Daniel K.},
	urldate = {2020-05-24},
	date = {2015},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.25240},
	keywords = {compressed sensing, dynamic {MRI}, for-reference, low-rank matrix completion, sparsity, to-read}
}

@article{roohi_multi-dimensional_2017,
	title = {Multi-dimensional low rank plus sparse decomposition for reconstruction of under-sampled dynamic {MRI}},
	volume = {63},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320316302965},
	doi = {10.1016/j.patcog.2016.09.040},
	abstract = {In this paper, we introduce a multi-dimensional approach to the problem of reconstruction of {MR} image sequences that are highly undersampled in k-space. By formulating the reconstruction as a high-order low rank tensor plus sparse tensor decomposition problem, we propose an efficient numerical algorithm based on the alternating direction method of multipliers ({ADMM}) to solve the optimization. Using Tucker representation, the sparse component is learnt efficiently with different sparsifying matrices along the modes of dynamic {MR} data. To estimate the low rank tensor, a convex cost function is defined to be the weighted sum of nuclear norms of its 3 unfolding matrices. Through extensive experimental results we show that our proposed method achieves superior reconstruction quality, compared to the state-of-the-art reconstruction methods.},
	pages = {667--679},
	journaltitle = {Pattern Recognition},
	shortjournal = {Pattern Recognition},
	author = {Roohi, Shahrooz F. and Zonoobi, Dornoosh and Kassim, Ashraf A. and Jaremko, Jacob L.},
	urldate = {2020-05-24},
	date = {2017-03-01},
	langid = {english},
	keywords = {Compressive sensing, Dynamic 3D {MRI}, Image reconstruction, Low-rank and sparse tensor decomposition}
}

@article{ong_extreme_2020,
	title = {Extreme {MRI}: Large-scale volumetric dynamic imaging from continuous non-gated acquisitions},
	volume = {n/a},
	rights = {¬© 2020 International Society for Magnetic Resonance in Medicine},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.28235},
	doi = {10.1002/mrm.28235},
	shorttitle = {Extreme {MRI}},
	abstract = {Purpose To develop a framework to reconstruct large-scale volumetric dynamic {MRI} from rapid continuous and non-gated acquisitions, with applications to pulmonary and dynamic contrast-enhanced ({DCE}) imaging. Theory and Methods The problem considered here requires recovering 100 gigabytes of dynamic volumetric image data from a few gigabytes of k-space data, acquired continuously over several minutes. This reconstruction is vastly under-determined, heavily stressing computing resources as well as memory management and storage. To overcome these challenges, we leverage intrinsic three-dimensional (3D) trajectories, such as 3D radial and 3D cones, with ordering that incoherently cover time and k-space over the entire acquisition. We then propose two innovations: (a) A compressed representation using multiscale low-rank matrix factorization that constrains the reconstruction problem, and reduces its memory footprint. (b) Stochastic optimization to reduce computation, improve memory locality, and minimize communications between threads and processors. We demonstrate the feasibility of the proposed method on {DCE} imaging acquired with a golden-angle ordered 3D cones trajectory and pulmonary imaging acquired with a bit-reversed ordered 3D radial trajectory. We compare it with ‚Äúsoft-gated' dynamic reconstruction for {DCE} and respiratory-resolved reconstruction for pulmonary imaging. Results The proposed technique shows transient dynamics that are not seen in gating-based methods. When applied to datasets with irregular, or non-repetitive motions, the proposed method displays sharper image features. Conclusions We demonstrated a method that can reconstruct massive 3D dynamic image series in the extreme undersampling and extreme computation setting.},
	pages = {1-- 18},
	issue = {n/a},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Ong, Frank and Zhu, Xucheng and Cheng, Joseph Y. and Johnson, Kevin M. and Larson, Peder E. Z. and Vasanawala, Shreyas S. and Lustig, Michael},
	urldate = {2020-05-25},
	date = {2020-04},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.28235},
	keywords = {{DCE}-{MRI}, Electrical Engineering and Systems Science - Image and Video Processing, Physics - Medical Physics, Pulmonary {MRI}, already-read, multiscale low rank, stochastic optimization, volumetric dynamic {MRI}}
}

@article{ong_extreme_2020-1,
	title = {Extreme {MRI}: Large-Scale Volumetric Dynamic Imaging from Continuous Non-Gated Acquisitions},
	url = {http://arxiv.org/abs/1909.13482},
	shorttitle = {Extreme {MRI}},
	abstract = {Purpose: To develop a framework to reconstruct large-scale volumetric dynamic {MRI} from rapid continuous and non-gated acquisitions, with applications to pulmonary and dynamic contrast enhanced ({DCE}) imaging. Theory and Methods: The problem considered here requires recovering hundred-gigabytes of dynamic volumetric image data from a few gigabytes of k-space data, acquired continuously over several minutes. This reconstruction is vastly under-determined, heavily stressing computing resources as well as memory management and storage. To overcome these challenges, we leverage intrinsic three dimensional (3D) trajectories, such as 3D radial and 3D cones, with ordering that incoherently cover time and k-space over the entire acquisition. We then propose two innovations: (1) A compressed representation using multi-scale low rank matrix factorization that constrains the reconstruction problem, and reduces its memory footprint. (2) Stochastic optimization to reduce computation, improve memory locality, and minimize communications between threads and processors. We demonstrate the feasibility of the proposed method on {DCE} imaging acquired with a golden-angle ordered 3D cones trajectory and pulmonary imaging acquired with a bit-reversed ordered 3D radial trajectory. We compare it with "soft-gated" dynamic reconstruction for {DCE} and respiratory resolved reconstruction for pulmonary imaging. Results: The proposed technique shows transient dynamics that are not seen in gating based methods. When applied to datasets with irregular, or non-repetitive motions, the proposed method displays sharper image features. Conclusion: We demonstrated a method that can reconstruct massive 3D dynamic image series in the extreme undersampling and extreme computation setting.},
	journaltitle = {{arXiv}:1909.13482 [physics]},
	author = {Ong, Frank and Zhu, Xucheng and Cheng, Joseph Y. and Johnson, Kevin M. and Larson, Peder E. Z. and Vasanawala, Shreyas S. and Lustig, Michael},
	urldate = {2020-05-25},
	date = {2020-02-05},
	eprinttype = {arxiv},
	eprint = {1909.13482},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Physics - Medical Physics}
}

@article{mccoy_convexity_2014,
	title = {Convexity in Source Separation : Models, geometry, and algorithms},
	volume = {31},
	issn = {1558-0792},
	doi = {10.1109/MSP.2013.2296605},
	shorttitle = {Convexity in Source Separation},
	abstract = {Source separation, or demixing, is the process of extracting multiple components entangled within a signal. Contemporary signal processing presents a host of difficult source separation problems, from interference cancellation to background subtraction, blind deconvolution, and even dictionary learning. Despite the recent progress in each of these applications, advances in high-throughput sensor technology place demixing algorithms under pressure to accommodate extremely high-dimensional signals, separate an ever larger number of sources, and cope with more sophisticated signal and mixing models. These difficulties are exacerbated by the need for real-time action in automated decision-making systems.},
	pages = {87--95},
	number = {3},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {{McCoy}, Michael B. and Cevher, Volkan and Dinh, Quoc Tran and Asaei, Afsaneh and Baldassarre, Luca},
	date = {2014-05},
	note = {Conference Name: {IEEE} Signal Processing Magazine},
	keywords = {Algorithm design and analysis, Atomic measurements, Convex functions, Principal component analysis, Signal processing algorithms, Source separation, Sparse matrices, automated decision-making systems, background subtraction, blind deconvolution, contemporary signal processing, demixing algorithms, dictionary learning, high-throughput sensor technology, interference cancellation, interference suppression, signal processing, source separation, source separation problems}
}

@article{mccoy_sharp_2014,
	title = {Sharp Recovery Bounds for Convex Demixing, with Applications},
	volume = {14},
	issn = {1615-3383},
	url = {https://doi.org/10.1007/s10208-014-9191-2},
	doi = {10.1007/s10208-014-9191-2},
	abstract = {Demixing refers to the challenge of identifying two structured signals given only the sum of the two signals and prior information about their structures. Examples include the problem of separating a signal that is sparse with respect to one basis from a signal that is sparse with respect to a second basis, and the problem of decomposing an observed matrix into a low-rank matrix plus a sparse matrix. This paper describes and analyzes a framework, based on convex optimization, for solving these demixing problems, and many others. This work introduces a randomized signal model that ensures that the two structures are incoherent, i.e., generically oriented. For an observation from this model, this approach identifies a summary statistic that reflects the complexity of a particular signal. The difficulty of separating two structured, incoherent signals depends only on the total complexity of the two structures. Some applications include (1) demixing two signals that are sparse in mutually incoherent bases, (2) decoding spread-spectrum transmissions in the presence of impulsive errors, and (3) removing sparse corruptions from a low-rank matrix. In each case, the theoretical analysis of the convex demixing method closely matches its empirical behavior.},
	pages = {503--567},
	number = {3},
	journaltitle = {Foundations of Computational Mathematics},
	shortjournal = {Found Comput Math},
	author = {{McCoy}, Michael B. and Tropp, Joel A.},
	urldate = {2020-05-25},
	date = {2014-06-01},
	langid = {english}
}

@article{mccoy_achievable_2013,
	title = {The achievable performance of convex demixing},
	url = {http://arxiv.org/abs/1309.7478},
	abstract = {Demixing is the problem of identifying multiple structured signals from a superimposed, undersampled, and noisy observation. This work analyzes a general framework, based on convex optimization, for solving demixing problems. When the constituent signals follow a generic incoherence model, this analysis leads to precise recovery guarantees. These results admit an attractive interpretation: each signal possesses an intrinsic degrees-of-freedom parameter, and demixing can succeed if and only if the dimension of the observation exceeds the total degrees of freedom present in the observation.},
	journaltitle = {{arXiv}:1309.7478 [cs, math]},
	author = {{McCoy}, Michael B. and Tropp, Joel A.},
	urldate = {2020-05-25},
	date = {2013-09-28},
	eprinttype = {arxiv},
	eprint = {1309.7478},
	note = {version: 1},
	keywords = {94A15, 90C25, 60D05, 94B75, Computer Science - Information Theory, Mathematics - Optimization and Control}
}

@article{nakarmi_accelerating_2016,
	title = {{ACCELERATING} {DYNAMIC} {MAGNETIC} {RESONANCE} {IMAGING} {BY} {NONLINEAR} {SPARSE} {CODING}},
	volume = {2016},
	issn = {1945-7928},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6839784/},
	doi = {10.1109/ISBI.2016.7493319},
	abstract = {Although being high-dimensional, dynamic magnetic resonance images usually lie on low-dimensional manifolds. Nonlinear models have been shown to capture well that latent low-dimensional nature of data, and can thus lead to improvements in the quality of constrained recovery algorithms. This paper advocates a novel reconstruction algorithm for dynamic magnetic resonance imaging ({dMRI}) based on nonlinear dictionary learned from low-spatial but high-temporal resolution images. The nonlinear dictionary is initially learned using kernel dictionary learning, and the proposed algorithm subsequently alternates between sparsity enforcement in the feature space and the data-consistency constraint in the original input space. Extensive numerical tests demonstrate that the proposed scheme is superior to popular methods that use linear dictionaries learned from the same set of training data.},
	pages = {510--513},
	journaltitle = {Proceedings. {IEEE} International Symposium on Biomedical Imaging},
	shortjournal = {Proc {IEEE} Int Symp Biomed Imaging},
	author = {Nakarmi, Ukash and Zhou, Yihang and Lyu, Jingyuan and Slavakis, Konstantinos and Ying, Leslie},
	urldate = {2020-05-25},
	date = {2016-04},
	pmid = {31709030},
	pmcid = {PMC6839784}
}

@article{tremoulheac_dynamic_2014,
	title = {Dynamic {MR} Image Reconstruction‚ÄìSeparation From Undersampled (\${\textbackslash}bf k,t\$)-Space via Low-Rank Plus Sparse Prior},
	volume = {33},
	issn = {1558-254X},
	doi = {10.1109/TMI.2014.2321190},
	abstract = {Dynamic magnetic resonance imaging ({MRI}) is used in multiple clinical applications, but can still benefit from higher spatial or temporal resolution. A dynamic {MR} image reconstruction method from partial ( k, t)-space measurements is introduced that recovers and inherently separates the information in the dynamic scene. The reconstruction model is based on a low-rank plus sparse decomposition prior, which is related to robust principal component analysis. An algorithm is proposed to solve the convex optimization problem based on an alternating direction method of multipliers. The method is validated with numerical phantom simulations and cardiac {MRI} data against state of the art dynamic {MRI} reconstruction methods. Results suggest that using the proposed approach as a means of regularizing the inverse problem remains competitive with state of the art reconstruction techniques. Additionally, the decomposition induced by the reconstruction is shown to help in the context of motion estimation in dynamic contrast enhanced {MRI}.},
	pages = {1689--1701},
	number = {8},
	journaltitle = {{IEEE} Transactions on Medical Imaging},
	author = {Tr√©moulh√©ac, Benjamin and Dikaios, Nikolaos and Atkinson, David and Arridge, Simon R.},
	date = {2014-08},
	note = {Conference Name: {IEEE} Transactions on Medical Imaging},
	keywords = {Algorithms, Compressive sensing ({CS}), Heart, Humans, Image Processing, Computer-Assisted, Image reconstruction, Licenses, Magnetic Resonance Imaging, Magnetic resonance imaging, Matrix decomposition, Phantoms, Imaging, Principal Component Analysis, Robustness, Sparse matrices, alternating direction method, biomedical {MRI}, cardiac {MRI} data, cardiology, convex optimization problem, dynamic {MR} image reconstruction method, dynamic magnetic resonance ({MR}) imaging, dynamic magnetic resonance imaging, high spatial resolution, high temporal resolution, image reconstruction, inverse problem, inverse transforms, low-rank, medical image processing, motion estimation, numerical analysis, numerical phantom simulation, optimisation, partial (k,t )-space measurements, phantoms, principal component analysis, robust principal component analysis, sparse decomposition prior, sparsity, state of the art reconstruction techniques, undersampled (K,t )-space measurement}
}

@article{cai_singular_2008,
	title = {A Singular Value Thresholding Algorithm for Matrix Completion},
	url = {http://arxiv.org/abs/0810.3286},
	abstract = {This paper introduces a novel algorithm to approximate the matrix with minimum nuclear norm among all matrices obeying a set of convex constraints. This problem may be understood as the convex relaxation of a rank minimization problem, and arises in many important applications as in the task of recovering a large matrix from a small subset of its entries (the famous Netflix problem). Off-the-shelf algorithms such as interior point methods are not directly amenable to large problems of this kind with over a million unknown entries. This paper develops a simple first-order and easy-to-implement algorithm that is extremely efficient at addressing problems in which the optimal solution has low rank. The algorithm is iterative and produces a sequence of matrices (X{\textasciicircum}k, Y{\textasciicircum}k) and at each step, mainly performs a soft-thresholding operation on the singular values of the matrix Y{\textasciicircum}k. There are two remarkable features making this attractive for low-rank matrix completion problems. The first is that the soft-thresholding operation is applied to a sparse matrix; the second is that the rank of the iterates X{\textasciicircum}k is empirically nondecreasing. Both these facts allow the algorithm to make use of very minimal storage space and keep the computational cost of each iteration low. We provide numerical examples in which 1,000 by 1,000 matrices are recovered in less than a minute on a modest desktop computer. We also demonstrate that our approach is amenable to very large scale problems by recovering matrices of rank about 10 with nearly a billion unknowns from just about 0.4\% of their sampled entries. Our methods are connected with linearized Bregman iterations for l1 minimization, and we develop a framework in which one can understand these algorithms in terms of well-known Lagrange multiplier algorithms.},
	journaltitle = {{arXiv}:0810.3286 [math]},
	author = {Cai, Jian-Feng and Candes, Emmanuel J. and Shen, Zuowei},
	urldate = {2020-05-24},
	date = {2008-10-17},
	eprinttype = {arxiv},
	eprint = {0810.3286},
	keywords = {Mathematics - Optimization and Control}
}

@article{lingala_accelerated_2011,
	title = {Accelerated Dynamic {MRI} Exploiting Sparsity and Low-Rank Structure: k-t {SLR}},
	volume = {30},
	issn = {1558-254X},
	doi = {10.1109/TMI.2010.2100850},
	shorttitle = {Accelerated Dynamic {MRI} Exploiting Sparsity and Low-Rank Structure},
	abstract = {We introduce a novel algorithm to reconstruct dynamic magnetic resonance imaging ({MRI}) data from under-sampled k-t space data. In contrast to classical model based cine {MRI} schemes that rely on the sparsity or banded structure in Fourier space, we use the compact representation of the data in the Karhunen Louve transform ({KLT}) domain to exploit the correlations in the dataset. The use of the data-dependent {KL} transform makes our approach ideally suited to a range of dynamic imaging problems, even when the motion is not periodic. In comparison to current {KLT}-based methods that rely on a two-step approach to first estimate the basis functions and then use it for reconstruction, we pose the problem as a spectrally regularized matrix recovery problem. By simultaneously determining the temporal basis functions and its spatial weights from the entire measured data, the proposed scheme is capable of providing high quality reconstructions at a range of accelerations. In addition to using the compact representation in the {KLT} domain, we also exploit the sparsity of the data to further improve the recovery rate. Validations using numerical phantoms and in vivo cardiac perfusion {MRI} data demonstrate the significant improvement in performance offered by the proposed scheme over existing methods.},
	pages = {1042--1054},
	number = {5},
	journaltitle = {{IEEE} Transactions on Medical Imaging},
	author = {Lingala, Sajan Goud and Hu, Yue and {DiBella}, Edward and Jacob, Mathews},
	date = {2011-05},
	note = {Conference Name: {IEEE} Transactions on Medical Imaging},
	keywords = {Algorithms, Computer Simulation, Data driven transforms, Fourier space, Heart, Heuristic algorithms, Humans, Image Processing, Computer-Assisted, Image reconstruction, Karhunen Louve transform domain, Karhunen-Loeve transforms, Magnetic Resonance Imaging, Cine, Magnetic resonance imaging, Minimization, Models, Cardiovascular, Optimization, Phantoms, Imaging, Reproducibility of Results, Respiratory Mechanics, Signal Processing, Computer-Assisted, Transforms, accelerated dynamic {MRI} exploiting sparsity, biomedical {MRI}, cardiology, classical model, dynamic magnetic resonance imaging ({MRI}), image reconstruction, in vivo cardiac perfusion {MRI} data, k-t {SLR}, low rank and sparse matrix recovery, low-rank structure, medical image processing, numerical analysis, numerical phantoms, phantoms, spectrally regularized matrix recovery problem, undersampled k-t space data}
}

@article{gabay_dual_1976,
	title = {A dual algorithm for the solution of nonlinear variational problems via finite element approximation},
	volume = {2},
	issn = {0898-1221},
	url = {http://www.sciencedirect.com/science/article/pii/0898122176900031},
	doi = {10.1016/0898-1221(76)90003-1},
	abstract = {For variational problems of the form Infv‚ààV\{f(Av)+g(v)\}, we propose a dual method which decouples the difficulties relative to the functionals f and g from the possible ill-conditioning effects of the linear operator A. The approach is based on the use of an Augmented Lagrangian functional and leads to an efficient and simply implementable algorithm. We study also the finite element approximation of such problems, compatible with the use of our algorithm. The method is finally applied to solve several problems of continuum mechanics.},
	pages = {17--40},
	number = {1},
	journaltitle = {Computers \& Mathematics with Applications},
	shortjournal = {Computers \& Mathematics with Applications},
	author = {Gabay, Daniel and Mercier, Bertrand},
	urldate = {2020-05-23},
	date = {1976-01-01},
	langid = {english}
}

@article{powell_method_1969,
	title = {A method for nonlinear constraints in minimization problems},
	url = {https://ci.nii.ac.jp/naid/20000922074/},
	pages = {283--298},
	journaltitle = {Optimization},
	author = {{POWELL}, M. J. D.},
	urldate = {2020-05-23},
	date = {1969},
	note = {Publisher: Academic Press}
}

@article{hestenes_multiplier_1969,
	title = {Multiplier and gradient methods},
	volume = {4},
	issn = {1573-2878},
	url = {https://doi.org/10.1007/BF00927673},
	doi = {10.1007/BF00927673},
	abstract = {The main purpose of this paper is to suggest a method for finding the minimum of a functionf(x) subject to the constraintg(x)=0. The method consists of replacingf {byF}=f+Œªg+1/2cg2, wherec is a suitably large constant, and computing the appropriate value of the Lagrange multiplier. Only the simplest algorithm is presented. The remaining part of the paper is devoted to a survey of known methods for finding unconstrained minima, with special emphasis on the various gradient techniques that are available. This includes Newton's method and the method of conjugate gradients.},
	pages = {303--320},
	number = {5},
	journaltitle = {Journal of Optimization Theory and Applications},
	shortjournal = {J Optim Theory Appl},
	author = {Hestenes, Magnus R.},
	urldate = {2020-05-23},
	date = {1969-11-01},
	langid = {english}
}

@article{taylor_exact_2017,
	title = {Exact Worst-Case Performance of First-Order Methods for Composite Convex Optimization},
	volume = {27},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/16M108104X},
	doi = {10.1137/16M108104X},
	abstract = {We provide a framework for computing the exact worst-case performance of any algorithm belonging to a broad class of oracle-based first-order methods for composite convex optimization, including those performing explicit, projected, proximal, conditional, and inexact (sub)gradient steps. We simultaneously obtain tight worst-case guarantees and explicit instances of optimization problems on which the algorithm reaches this worst-case. We achieve this by reducing the computation of the worst-case to solving a convex semidefinite program, generalizing previous works on performance estimation by Drori and Teboulle  [Math. Program., 145 (2014), pp. 451--482] and the authors [A. B. Taylor, J. M. Hendrickx, and F. Glineur, Math. Program., 161 (2017), pp. 307--345]. We use these developments to obtain a tighter analysis of the proximal point algorithm and of several variants of fast proximal gradient, conditional gradient, subgradient, and alternating projection methods. In particular, we present a new analytical worst-case guarantee for the proximal point algorithm that is twice better than previously known and improve the standard worst-case guarantee for the conditional gradient method by more than a factor of two. We also show how the optimized gradient method proposed by Kim and Fessler [Math. Program., 159 (2016), pp. 81--107] can be extended by incorporating a projection or a proximal operator, which leads to an algorithm that converges in the worst-case twice as fast as the standard accelerated proximal gradient method [A. Beck and M. Teboulle, {SIAM} J. Imaging Sci., 2 (2009), pp. 183--202].},
	pages = {1283--1313},
	number = {3},
	journaltitle = {{SIAM} Journal on Optimization},
	shortjournal = {{SIAM} J. Optim.},
	author = {Taylor, Adrien B. and Hendrickx, Julien M. and Glineur, Fran√ßois},
	urldate = {2020-05-23},
	date = {2017-01-01},
	note = {Publisher: Society for Industrial and Applied Mathematics}
}

@article{drori_performance_2014,
	title = {Performance of first-order methods for smooth convex minimization: a novel approach},
	volume = {145},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-013-0653-0},
	doi = {10.1007/s10107-013-0653-0},
	shorttitle = {Performance of first-order methods for smooth convex minimization},
	abstract = {We introduce a novel approach for analyzing the worst-case performance of first-order black-box optimization methods. We focus on smooth unconstrained convex minimization over the Euclidean space. Our approach relies on the observation that by definition, the worst-case behavior of a black-box optimization method is by itself an optimization problem, which we call the performance estimation problem ({PEP}). We formulate and analyze the {PEP} for two classes of first-order algorithms. We first apply this approach on the classical gradient method and derive a new and tight analytical bound on its performance. We then consider a broader class of first-order black-box methods, which among others, include the so-called heavy-ball method and the fast gradient schemes. We show that for this broader class, it is possible to derive new bounds on the performance of these methods by solving an adequately relaxed convex semidefinite {PEP}. Finally, we show an efficient procedure for finding optimal step sizes which results in a first-order black-box method that achieves best worst-case performance.},
	pages = {451--482},
	number = {1},
	journaltitle = {Mathematical Programming},
	shortjournal = {Math. Program.},
	author = {Drori, Yoel and Teboulle, Marc},
	urldate = {2020-05-22},
	date = {2014-06-01},
	langid = {english}
}

@article{beck_fast_2009,
	title = {A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems},
	volume = {2},
	url = {https://epubs.siam.org/doi/abs/10.1137/080716542},
	doi = {10.1137/080716542},
	abstract = {We consider the class of iterative shrinkage-thresholding algorithms ({ISTA}) for solving linear inverse problems arising in signal/image processing. This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data. However, such methods are also known to converge quite slowly. In this paper we present a new fast iterative shrinkage-thresholding algorithm ({FISTA}) which preserves the computational simplicity of {ISTA} but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of {FISTA} which is shown to be faster than {ISTA} by several orders of magnitude.},
	pages = {183--202},
	number = {1},
	journaltitle = {{SIAM} Journal on Imaging Sciences},
	shortjournal = {{SIAM} J. Imaging Sci.},
	author = {Beck, Amir and Teboulle, Marc},
	urldate = {2020-05-23},
	date = {2009-01-01},
	note = {Publisher: Society for Industrial and Applied Mathematics}
}

@article{bruck_weak_1977,
	title = {On the weak convergence of an ergodic iteration for the solution of variational inequalities for monotone operators in Hilbert space},
	volume = {61},
	issn = {10.1016/0022-247X(77)90152-4},
	url = {https://core.ac.uk/display/82410520},
	doi = {10.1016/0022-247X(77)90152-4},
	journaltitle = {Journal of Mathematical Analysis and Applications},
	author = {Bruck, Ronald E.},
	urldate = {2020-05-23},
	date = {1977},
	langid = {english},
	note = {Publisher: Published by Elsevier Inc.}
}

@article{martinet_breve_1970,
	title = {Br√®ve communication. R√©gularisation d'in√©quations variationnelles par approximations successives},
	volume = {4},
	url = {http://www.numdam.org/item/?id=M2AN_1970__4_3_154_0},
	pages = {154--158},
	issue = {R3},
	journaltitle = {{ESAIM}: Mathematical Modelling and Numerical Analysis - Mod√©lisation Math√©matique et Analyse Num√©rique},
	author = {Martinet, B.},
	urldate = {2020-05-23},
	date = {1970},
	langid = {english}
}

@book{shor_minimization_2012,
	title = {Minimization Methods for Non-Differentiable Functions},
	isbn = {978-3-642-82118-9},
	abstract = {In recent years much attention has been given to the development of auto matic systems of planning, design and control in various branches of the national economy. Quality of decisions is an issue which has come to the forefront, increasing the significance of optimization algorithms in math ematical software packages for al,ltomatic systems of various levels and pur poses. Methods for minimizing functions with discontinuous gradients are gaining in importance and the {\textasciitilde}xperts in the computational methods of mathematical programming tend to agree that progress in the development of algorithms for minimizing nonsmooth functions is the key to the con struction of efficient techniques for solving large scale problems. This monograph summarizes to a certain extent fifteen years of the author's work on developing generalized gradient methods for nonsmooth minimization. This work started in the department of economic cybernetics of the Institute of Cybernetics of the Ukrainian Academy of Sciences under the supervision of V.S. Mikhalevich, a member of the Ukrainian Academy of Sciences, in connection with the need for solutions to important, practical problems of optimal planning and design. In Chap. I we describe basic classes of nonsmooth functions that are dif ferentiable almost everywhere, and analyze various ways of defining generalized gradient sets. In Chap. 2 we study in detail various versions of the su bgradient method, show their relation to the methods of Fejer-type approximations and briefly present the fundamentals of e-subgradient methods.},
	pagetotal = {171},
	publisher = {Springer Science \& Business Media},
	author = {Shor, N. Z.},
	date = {2012-12-06},
	langid = {english},
	note = {Google-Books-{ID}: 4ePnCAAAQBAJ},
	keywords = {Language Arts \& Disciplines / Library \& Information Science / General, Mathematics / Calculus, Mathematics / Functional Analysis, Mathematics / General, Science / System Theory}
}

@article{polak_note_1969,
	title = {Note sur la convergence de m√©thodes de directions conjugu√©es},
	volume = {3},
	url = {http://www.numdam.org/item/?id=M2AN_1969__3_1_35_0},
	pages = {35--43},
	issue = {R1},
	journaltitle = {{ESAIM}: Mathematical Modelling and Numerical Analysis - Mod√©lisation Math√©matique et Analyse Num√©rique},
	author = {Polak, E. and Ribiere, G.},
	urldate = {2020-05-23},
	date = {1969},
	langid = {english}
}

@article{dai_nonlinear_1999,
	title = {A Nonlinear Conjugate Gradient Method with a Strong Global Convergence Property},
	volume = {10},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/S1052623497318992},
	doi = {10.1137/S1052623497318992},
	abstract = {Conjugate gradient methods are widely used for unconstrained optimization, especially large scale problems. The strong Wolfe conditions are usually used in the analyses and implementations of conjugate gradient methods. This paper presents a new version of the conjugate gradient method, which converges globally, provided the line search satisfies the standard Wolfe conditions. The conditions on the objective function are also weak, being similar to those required by the Zoutendijk condition.},
	pages = {177--182},
	number = {1},
	journaltitle = {{SIAM} Journal on Optimization},
	shortjournal = {{SIAM} J. Optim.},
	author = {Dai, Y. H. and Yuan, Y.},
	urldate = {2020-05-23},
	date = {1999-01-01},
	note = {Publisher: Society for Industrial and Applied Mathematics}
}

@article{fletcher_function_1964,
	title = {Function minimization by conjugate gradients},
	volume = {7},
	issn = {0010-4620},
	url = {https://academic.oup.com/comjnl/article/7/2/149/335311},
	doi = {10.1093/comjnl/7.2.149},
	abstract = {Abstract.  A quadratically convergent gradient method for locating an unconstrained local minimum of a function of several variables is described. Particular ad},
	pages = {149--154},
	number = {2},
	journaltitle = {The Computer Journal},
	shortjournal = {Comput J},
	author = {Fletcher, R. and Reeves, C. M.},
	urldate = {2020-05-23},
	date = {1964-01-01},
	langid = {english},
	note = {Publisher: Oxford Academic}
}
@artwork{alexandrov_illustration_2007,
	title = {Illustration of conjugate gradient method},
	rights = {Public domain},
	url = {https://commons.wikimedia.org/wiki/File:Conjugate_gradient_illustration.svg},
	author = {Alexandrov, Oleg},
	urldate = {2020-05-23},
	date = {2007-06-20}
}

@artwork{simionescu_illustration_2006,
	title = {Illustration descente de gradient},
	rights = {Permission is granted to copy, distribute and/or modify this document under the terms of the {GNU} Free Documentation License, Version 1.2 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled {GNU} Free Documentation License. Subject to disclaimers.http://www.gnu.org/copyleft/fdl.{htmlGFDLGNU} Free Documentation Licensetruetrue},
	url = {https://commons.wikimedia.org/wiki/File:Banana-SteepDesc.gif},
	author = {Simionescu, P. A.},
	urldate = {2020-05-23},
	date = {2006-11-17}
}

@article{hestenes_methods_1952,
	title = {Methods of conjugate gradients for solving linear systems},
	volume = {49},
	abstract = {An iterative algorithm is given for solving a system Ax= k of n linear equations in n unknowns. The solution is given in n steps. It is shown that this method is a special case of a very general met hod which also includes Gaussian elimination . These general
algorithms are essentially algorithms for findin g an n dimensional ellipsoid. Connections a re made wit h the theory of orthogonal polynomials and continued fractions.},
	pages = {409--436},
	number = {6},
	journaltitle = {Journal of Research of the National Bureau of Standards},
	author = {Hestenes, M R and Stiefel, E},
	date = {1952-12},
	langid = {english}
}

@inproceedings{sutskever_importance_2013,
	title = {On the importance of initialization and momentum in deep learning},
	url = {http://proceedings.mlr.press/v28/sutskever13.pdf},
	abstract = {Deep and recurrent neural networks ({DNNs} and {RNNs} respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both {DNNs} and {RNNs} (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We Ô¨Ånd that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.},
	pages = {1139--1147},
	booktitle = {International conference on machine learning},
	author = {Sutskever, Ilya and Martens, James and Dahl, George},
	date = {2013},
	langid = {english}
}

@article{drori_exact_2017,
	title = {The exact information-based complexity of smooth convex minimization},
	volume = {39},
	issn = {0885-064X},
	url = {http://www.sciencedirect.com/science/article/pii/S0885064X16301066},
	doi = {10.1016/j.jco.2016.11.001},
	abstract = {We obtain a new lower bound on the information-based complexity of first-order minimization of smooth and convex functions. We show that the bound matches the worst-case performance of the recently introduced Optimized Gradient Method (Drori and Teboulle, 2013; Kim and Fessler, 2015), thereby establishing that the bound is tight and can be realized by an efficient algorithm. The proof is based on a novel construction technique of smooth and convex functions.},
	pages = {1--16},
	journaltitle = {Journal of Complexity},
	shortjournal = {Journal of Complexity},
	author = {Drori, Yoel},
	urldate = {2020-05-23},
	date = {2017-04-01},
	langid = {english},
	keywords = {Complexity, Convex optimization, Information-based complexity, Rate of convergence}
}

@article{kim_convergence_2017,
	title = {On the Convergence Analysis of the Optimized Gradient Method},
	volume = {172},
	issn = {1573-2878},
	url = {https://doi.org/10.1007/s10957-016-1018-7},
	doi = {10.1007/s10957-016-1018-7},
	abstract = {This paper considers the problem of unconstrained minimization of smooth convex functions having Lipschitz continuous gradients with known Lipschitz constant. We recently proposed the optimized gradient method for this problem and showed that it has a worst-case convergence bound for the cost function decrease that is twice as small as that of Nesterov‚Äôs fast gradient method, yet has a similarly efficient practical implementation. Drori showed recently that the optimized gradient method has optimal complexity for the cost function decrease over the general class of first-order methods. This optimality makes it important to study fully the convergence properties of the optimized gradient method. The previous worst-case convergence bound for the optimized gradient method was derived for only the last iterate of a secondary sequence. This paper provides an analytic convergence bound for the primary sequence generated by the optimized gradient method. We then discuss additional convergence properties of the optimized gradient method, including the interesting fact that the optimized gradient method has two types of worst-case functions: a piecewise affine-quadratic function and a quadratic function. These results help complete the theory of an optimal first-order method for smooth convex minimization.},
	pages = {187--205},
	number = {1},
	journaltitle = {Journal of Optimization Theory and Applications},
	shortjournal = {J Optim Theory Appl},
	author = {Kim, Donghwan and Fessler, Jeffrey A.},
	urldate = {2020-05-23},
	date = {2017-01-01},
	langid = {english}
}

@unpublished{kim_optimal_2017,
	title = {Optimal Ô¨Årst-order minimization methods},
	url = {https://web.eecs.umich.edu/~fessler/papers/files/talk/17/csp.pdf},
	author = {Kim, Donghwan and Fessler, JeÔ¨Ärey A},
	date = {2017-12-07},
	langid = {english}
}

@article{nesterov_method_1983,
	title = {A method for solving the convex programming problem with convergence rate O(1/k{\textasciicircum}2)},
	volume = {269},
	url = {https://ci.nii.ac.jp/naid/10029946121/},
	pages = {543--547},
	journaltitle = {Dokl. Akad. Nauk {SSSR}},
	author = {Nesterov, Y. E.},
	urldate = {2020-05-23},
	date = {1983}
}

@article{polyak_methods_1964,
	title = {Some methods of speeding up the convergence of iteration methods},
	volume = {4},
	issn = {0041-5553},
	url = {http://www.sciencedirect.com/science/article/pii/0041555364901375},
	doi = {10.1016/0041-5553(64)90137-5},
	abstract = {For the solution of the functional equation P (x) = 0 (1) (where P is an operator, usually linear, from B into B, and B is a Banach space) iteration methods are generally used. These consist of the construction of a series x0, ‚Ä¶, xn, ‚Ä¶, which converges to the solution (see, for example [1]). Continuous analogues of these methods are also known, in which a trajectory x(t), 0 ‚©Ω t ‚©Ω ‚àû is constructed, which satisfies the ordinary differential equation in B and is such that x(t) approaches the solution of (1) as t ‚Üí ‚àû (see [2]). We shall call the method a k-step method if for the construction of each successive iteration xn+1 we use k previous iterations xn, ‚Ä¶, xn‚àík+1. The same term will also be used for continuous methods if x(t) satisfies a differential equation of the k-th order or k-th degree. Iteration methods which are more widely used are one-step (e.g. methods of successive approximations). They are generally simple from the calculation point of view but often converge very slowly. This is confirmed both by the evaluation of the speed of convergence and by calculation in practice (for more details see below). Therefore the question of the rate of convergence is most important. Some multistep methods, which we shall consider further, which are only slightly more complicated than the corresponding one-step methods, make it possible to speed up the convergence substantially. Note that all the methods mentioned below are applicable also to the problem of minimizing the differentiable functional (x) in Hilbert space, so long as this problem reduces to the solution of the equation grad (x) = 0.},
	pages = {1--17},
	number = {5},
	journaltitle = {{USSR} Computational Mathematics and Mathematical Physics},
	shortjournal = {{USSR} Computational Mathematics and Mathematical Physics},
	author = {Polyak, B. T.},
	urldate = {2020-05-22},
	date = {1964-01-01},
	langid = {english}
}

@online{chandradevan_evolution_2017,
	title = {The Evolution of Gradient Descend Optimization Algorithm},
	url = {https://medium.com/@ramrajchandradevan/the-evolution-of-gradient-descend-optimization-algorithm-4106a6702d39},
	abstract = {Most popular optimization technique used in nerual networks. Latest algorithms like ‚Äúlasagne‚Äôs‚Äù, ‚Äúcaffe‚Äôs‚Äù, and ‚Äúkera‚Äôs‚Äù considered to be‚Ä¶},
	titleaddon = {Medium},
	author = {Chandradevan, Ramraj},
	urldate = {2020-05-22},
	date = {2017-07-13},
	langid = {english},
	note = {Library Catalog: medium.com}
}

@book{polyak_introduction_1987,
	location = {New York},
	title = {Introduction to Optimization},
	isbn = {978-0-911575-14-9},
	abstract = {Text: English, Russian (translation)},
	pagetotal = {438},
	publisher = {Optimization Software},
	author = {Polyak, Boris T.},
	date = {1987-05-01}
}

@article{taylor_smooth_2017,
	title = {Smooth strongly convex interpolation and exact worst-case performance of first-order methods},
	volume = {161},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-016-1009-3},
	doi = {10.1007/s10107-016-1009-3},
	abstract = {We show that the exact worst-case performance of fixed-step first-order methods for unconstrained optimization of smooth (possibly strongly) convex functions can be obtained by solving convex programs. Finding the worst-case performance of a black-box first-order method is formulated as an optimization problem over a set of smooth (strongly) convex functions and initial conditions. We develop closed-form necessary and sufficient conditions for smooth (strongly) convex interpolation, which provide a finite representation for those functions. This allows us to reformulate the worst-case performance estimation problem as an equivalent finite dimension-independent semidefinite optimization problem, whose exact solution can be recovered up to numerical precision. Optimal solutions to this performance estimation problem provide both worst-case performance bounds and explicit functions matching them, as our smooth (strongly) convex interpolation procedure is constructive. Our works build on those of Drori and Teboulle (Math Program 145(1‚Äì2):451‚Äì482, 2014) who introduced and solved relaxations of the performance estimation problem for smooth convex functions. We apply our approach to different fixed-step first-order methods with several performance criteria, including objective function accuracy and gradient norm. We conjecture several numerically supported worst-case bounds on the performance of the fixed-step gradient, fast gradient and optimized gradient methods, both in the smooth convex and the smooth strongly convex cases, and deduce tight estimates of the optimal step size for the gradient method.},
	pages = {307--345},
	number = {1},
	journaltitle = {Mathematical Programming},
	shortjournal = {Math. Program.},
	author = {Taylor, Adrien B. and Hendrickx, Julien M. and Glineur, Fran√ßois},
	urldate = {2020-05-22},
	date = {2017-01-01},
	langid = {english}
}

@article{wolfe_convergence_1969,
	title = {Convergence Conditions for Ascent Methods},
	volume = {11},
	issn = {0036-1445},
	url = {https://www.jstor.org/stable/2028111},
	abstract = {Liberal conditions on the steps of a "descent" method for finding extrema of a function are given; most known results are special cases.},
	pages = {226--235},
	number = {2},
	journaltitle = {{SIAM} Review},
	author = {Wolfe, Philip},
	urldate = {2020-05-22},
	date = {1969},
	note = {Publisher: Society for Industrial and Applied Mathematics}
}

@article{armijo_minimization_1966,
	title = {Minimization of functions having Lipschitz continuous first partial derivatives},
	volume = {16},
	url = {https://projecteuclid.org:443/euclid.pjm/1102995080},
	pages = {1--3},
	journaltitle = {Pacific Journal of Mathematics},
	shortjournal = {Pacific J. Math.},
	author = {Armijo, Larry},
	date = {1966}
}

@article{cauchy_methode_1847,
	title = {M√©thode g√©n√©rale pour la r√©solution des syst√®mes d‚Äô√©quations simultan√©es},
	volume = {25},
	pages = {536--538},
	journaltitle = {Comptes rendus hebdomadaires des s√©ances de l'Acad√©mie des sciences.},
	author = {Cauchy, Augustin-Louis},
	date = {1847}
}

@online{zhao_compressed_2014,
	title = {Compressed Sensing {MR} Image Reconstruction Exploiting {TGV} and Wavelet Sparsity},
	url = {https://www.hindawi.com/journals/cmmm/2014/958671/},
	abstract = {Compressed sensing ({CS}) based methods make it possible to reconstruct magnetic resonance ({MR}) images from undersampled measurements, which is known as {CS}-{MRI}. The reference-driven {CS}-{MRI} reconstruction schemes can further decrease the sampling ratio by exploiting the sparsity of the difference image between the target and the reference {MR} images in pixel domain. Unfortunately existing methods do not work well given that contrast changes are incorrectly estimated or motion compensation is inaccurate. In this paper, we propose to reconstruct {MR} images by utilizing the sparsity of the difference image between the target and the motion-compensated reference images in wavelet transform and gradient domains. The idea is attractive because it requires neither the estimation of the contrast changes nor multiple times motion compensations. In addition, we apply total generalized variation ({TGV}) regularization to eliminate the staircasing artifacts caused by conventional total variation ({TV}). Fast composite splitting algorithm ({FCSA}) is used to solve the proposed reconstruction problem in order to improve computational efficiency. Experimental results demonstrate that the proposed method can not only reduce the computational cost but also decrease sampling ratio or improve the reconstruction quality alternatively.},
	titleaddon = {Computational and Mathematical Methods in Medicine},
	type = {Research Article},
	author = {Zhao, Di and Du, Huiqian and Han, Yu and Mei, Wenbo},
	urldate = {2020-05-21},
	date = {2014},
	langid = {english},
	doi = {https://doi.org/10.1155/2014/958671},
	doi = {https://doi.org/10.1155/2014/958671},
	note = {{ISSN}: 1748-670X
Library Catalog: www.hindawi.com
Pages: e958671
Publisher: Hindawi
Volume: 2014}
}

@online{noauthor_mri_nodate,
	title = {{MRI} Angiography},
	url = {https://www.materprivate.ie/dublin/centre-services/all-services/mri-angiography/},
	titleaddon = {Mater Private Hospital},
	urldate = {2020-05-21}
}

@book{fornasier_theoretical_2010,
	title = {Theoretical Foundations and Numerical Methods for Sparse Recovery},
	isbn = {978-3-11-022615-7},
	abstract = {The present collection is the very first contribution of this type in the field of sparse recovery. Compressed sensing is one of the important facets of the broader concept presented in the book, which by now has made connections with other branches such as mathematical imaging, inverse problems, numerical analysis and simulation. The book consists of four lecture notes of courses given at the Summer School on "Theoretical Foundations and Numerical Methods for Sparse Recovery" held at the Johann Radon Institute for Computational and Applied Mathematics in Linz, Austria, in September 2009. This unique collection will be of value for a broad community and may serve as a textbook for graduate courses. From the contents: "Compressive Sensing and Structured Random Matrices" by Holger Rauhut "Numerical Methods for Sparse Recovery" by Massimo Fornasier "Sparse Recovery in Inverse Problems" by Ronny Ramlau and Gerd Teschke "An Introduction to Total Variation for Image Analysis" by Antonin Chambolle, Vicent Caselles, Daniel Cremers, Matteo Novaga and Thomas Pock},
	pagetotal = {351},
	publisher = {Walter de Gruyter},
	author = {Fornasier, Massimo},
	date = {2010-07-30},
	langid = {english},
	keywords = {Mathematics / Applied, Mathematics / Differential Equations / General, Mathematics / General, Mathematics / Numerical Analysis}
}

@article{cohen_compressed_2009,
	title = {Compressed sensing and best k-term approximation},
	volume = {22},
	issn = {0894-0347, 1088-6834},
	url = {https://www.ams.org/jams/2009-22-01/S0894-0347-08-00610-3/},
	doi = {10.1090/S0894-0347-08-00610-3},
	abstract = {Compressed sensing is a new concept in signal processing where one seeks to minimize the number of measurements to be taken from signals while still retaining the information necessary to approximate them well. The ideas have their origins in certain abstract results from functional analysis and approximation theory by Kashin but were recently brought into the forefront by the work of Cand√®s, Romberg, and Tao and of Donoho who constructed concrete algorithms and showed their promise in application. There remain several fundamental questions on both the theoretical and practical sides of compressed sensing. This paper is primarily concerned with one of these theoretical issues revolving around just how well compressed sensing can approximate a given signal from a given budget of fixed linear measurements, as compared to adaptive linear measurements. More precisely, we consider discrete signals , allocate linear measurements of , and we describe the range of for which these measurements encode enough information to recover in the sense of to the accuracy of best -term approximation. We also consider the problem of having such accuracy only with high probability.},
	pages = {211--231},
	number = {1},
	journaltitle = {Journal of the American Mathematical Society},
	shortjournal = {J. Amer. Math. Soc.},
	author = {Cohen, Albert and Dahmen, Wolfgang and {DeVore}, Ronald},
	urldate = {2020-05-15},
	date = {2009},
	langid = {english},
	keywords = {Compressed sensing, Gaussian and Bernoulli ensembles, Gelfand width, best ùëò-term approximation, instance optimal decoders, instance optimality in probability., mixed instance optimality, null space property, random matrices, restricted isometry property, ‚Ñì‚ÇÅ-minimization}
}

@article{gottschling_troublesome_2020,
	title = {The troublesome kernel: why deep learning for inverse problems is typically unstable},
	url = {http://arxiv.org/abs/2001.01258},
	shorttitle = {The troublesome kernel},
	abstract = {There is overwhelming empirical evidence that Deep Learning ({DL}) leads to unstable methods in applications ranging from image classification and computer vision to voice recognition and automated diagnosis in medicine. Recently, a similar instability phenomenon has been discovered when {DL} is used to solve certain problems in computational science, namely, inverse problems in imaging. In this paper we present a comprehensive mathematical analysis explaining the many facets of the instability phenomenon in {DL} for inverse problems. Our main results not only explain why this phenomenon occurs, they also shed light as to why finding a cure for instabilities is so difficult in practice. Additionally, these theorems show that instabilities are typically not rare events - rather, they can occur even when the measurements are subject to completely random noise - and consequently how easy it can be to destablise certain trained neural networks. We also examine the delicate balance between reconstruction performance and stability, and in particular, how {DL} methods may outperform state-of-the-art sparse regularization methods, but at the cost of instability. Finally, we demonstrate a counterintuitive phenomenon: training a neural network may generically not yield an optimal reconstruction method for an inverse problem.},
	journaltitle = {{arXiv}:2001.01258 [cs]},
	author = {Gottschling, Nina M. and Antun, Vegard and Adcock, Ben and Hansen, Anders C.},
	urldate = {2020-05-16},
	date = {2020-01-05},
	eprinttype = {arxiv},
	eprint = {2001.01258},
	keywords = {65R32, 94A08, 68T05, 65M12, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}

@book{foucart_mathematical_2013,
	title = {A Mathematical Introduction to Compressive Sensing},
	isbn = {978-0-8176-4947-0},
	url = {https://www.springer.com/gp/book/9780817649470},
	series = {Applied and Numerical Harmonic Analysis},
	abstract = {At the intersection of mathematics, engineering, and computer science sits the thriving field of compressive sensing. Based on the premise that data acquisition and compression can be performed simultaneously, compressive sensing finds applications in imaging, signal processing, and many other domains. In the areas of applied mathematics, electrical engineering, and theoretical computer science, an explosion of research activity has already followed the theoretical results that highlighted the efficiency of the basic principles. The elegant ideas behind these principles are also of independent interest to pure mathematicians.A Mathematical Introduction to Compressive Sensing gives a detailed account of the core theory upon which the field is build. With only moderate prerequisites, it is an excellent textbook for graduate courses in mathematics, engineering, and computer science. It also serves as a reliable resource for practitioners and researchers in these disciplines who want to acquire a careful understanding of the subject. A Mathematical Introduction to Compressive Sensing uses a mathematical perspective to present the core of the theory underlying compressive sensing.},
	publisher = {Birkh√§user Basel},
	author = {Foucart, Simon and Rauhut, Holger},
	urldate = {2020-05-14},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-0-8176-4948-7}
}

@article{candes_nearoptimal_2006,
	title = {Near‚ÄíOptimal Signal Recovery From Random Projections: Universal Encoding Strategies?},
	volume = {52},
	issn = {1557-9654},
	doi = {10.1109/TIT.2006.885507},
	abstract = {Suppose we are given a vector f in a class {FsubeRopfN} , e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr2) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector {\textbar}f{\textbar} (or of its coefficients in a fixed basis) obeys {\textbar}f{\textbar}(n){lesRmiddotn}-1p/, where R{\textgreater}0 and p{\textgreater}0. Suppose that we take measurements yk=langf\# ,Xkrang,k=1,...,K, where the Xk are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0{\textless}p{\textless}1 and with overwhelming probability, our reconstruction ft, defined as the solution to the constraints yk=langf\# ,Xkrang with minimal lscr1 norm, obeys parf-f\#parlscr2lesCp {middotRmiddot}(K/{logN})-r, r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed.},
	pages = {5406--5425},
	number = {12},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Cand√®s, Emmanuel and Tao, Terence},
	date = {2006-12}
}

@article{donoho_compressed_2006,
	title = {Compressed sensing},
	volume = {52},
	issn = {1557-9654},
	doi = {10.1109/TIT.2006.871582},
	abstract = {Suppose x is an unknown vector in Ropfm (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n=O(m1/4log5/2(m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an lscrp ball for 0{\textless}ples1. The N most important coefficients in that expansion allow reconstruction with lscr2 error O(N1/2-1p/). It is possible to design n=O(Nlog(m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of "random" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of lscrp balls in high-dimensional Euclidean space in the case 0{\textless}ples1, and give a criterion identifying near- optimal subspaces for Gel'fand n-widths. We show that "most" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces.},
	pages = {1289--1306},
	number = {4},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Donoho, David L.},
	date = {2006-04}
}

@article{candes_robust_2006,
	title = {Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information},
	volume = {52},
	issn = {1557-9654},
	doi = {10.1109/TIT.2005.862083},
	shorttitle = {Robust uncertainty principles},
	abstract = {This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f/spl isin/C/sup N/ and a randomly chosen set of frequencies /spl Omega/. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set /spl Omega/? A typical result of this paper is as follows. Suppose that f is a superposition of {\textbar}T{\textbar} spikes f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl delta/(t-/spl tau/) obeying {\textbar}T{\textbar}/spl les/C/sub M//spl middot/(log N)/sup -1/ /spl middot/ {\textbar}/spl Omega/{\textbar} for some constant C/sub M/{\textgreater}0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N/sup -M/), f can be reconstructed exactly as the solution to the /spl lscr//sub 1/ minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for C/sub M/ which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of {\textbar}T{\textbar} spikes may be recovered by convex programming from almost every set of frequencies of size O({\textbar}T{\textbar}/spl middot/{logN}). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N/sup -M/) would in general require a number of frequency samples at least proportional to {\textbar}T{\textbar}/spl middot/{logN}. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.},
	pages = {489--509},
	number = {2},
	journaltitle = {{IEEE} Transactions on Information Theory},
	author = {Candes, E.J. and Romberg, J. and Tao, T.},
	date = {2006-02},
	keywords = {Biomedical imaging, Convex optimization, Fourier analysis, Fourier coefficient, Frequency, Image reconstruction, Linear programming, Mathematics, Robustness, Sampling methods, Signal processing, Signal reconstruction, Uncertainty, convex optimization, convex programming, discrete-time signal, duality in optimization, free probability, image reconstruction, image sampling, incomplete frequency information, indeterminancy, linear programming, minimisation, minimization problem, nonlinear sampling theorem, piecewise constant object, piecewise constant techniques, probability, probability value, random matrices, robust uncertainty principle, signal reconstruction, signal sampling, sparse matrices, sparse random matrix, sparsity, total-variation minimization, trigonometric expansion, trigonometric expansions, uncertainty principle}
}

@inreference{noauthor_mm_2020,
	title = {{MM} algorithm},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=MM_algorithm&oldid=950831381},
	abstract = {The {MM} algorithm is an iterative optimization method which exploits the convexity of a function in order to find their maxima or minima. The {MM} stands for ‚ÄúMajorize-Minimization‚Äù or ‚ÄúMinorize-Maximization‚Äù, depending on whether the desired optimization is a maximization or a minimization. {MM} itself is not an algorithm, but a description of how to construct an optimization algorithm.
The expectation‚Äìmaximization algorithm can be treated as a special case of the {MM} algorithm.
However, in the {EM} algorithm conditional expectations are usually involved, while in the {MM} algorithm convexity and inequalities are the main focus, and it is easier to understand and apply in most cases.},
	booktitle = {Wikipedia},
	urldate = {2020-05-13},
	date = {2020-04-14},
	langid = {english},
	note = {Page Version {ID}: 950831381}
}

@online{noauthor_forschungszentrum_nodate,
	title = {Forschungszentrum J√ºlich - Comparison of methods for in vivo sodium imaging at 9.4 Tesla},
	url = {https://www.fz-juelich.de/inm/inm-4/EN/Forschung/MR-Physik/TeamNatrium/Methodenvergleich/_node.html},
	urldate = {2020-05-13}
}

@article{hamilton_recent_2017,
	title = {Recent advances in parallel imaging for {MRI}},
	volume = {101},
	issn = {0079-6565},
	url = {http://www.sciencedirect.com/science/article/pii/S0079656517300031},
	doi = {10.1016/j.pnmrs.2017.04.002},
	abstract = {Magnetic Resonance Imaging ({MRI}) is an essential technology in modern medicine. However, one of its main drawbacks is the long scan time needed to localize the {MR} signal in space to generate an image. This review article summarizes some basic principles and recent developments in parallel imaging, a class of image reconstruction techniques for shortening scan time. First, the fundamentals of {MRI} data acquisition are covered, including the concepts of k-space, undersampling, and aliasing. It is demonstrated that scan time can be reduced by sampling a smaller number of phase encoding lines in k-space; however, without further processing, the resulting images will be degraded by aliasing artifacts. Nearly all modern clinical scanners acquire data from multiple independent receiver coil arrays. Parallel imaging methods exploit properties of these coil arrays to separate aliased pixels in the image domain or to estimate missing k-space data using knowledge of nearby acquired k-space points. Three parallel imaging methods‚Äî{SENSE}, {GRAPPA}, and {SPIRiT}‚Äîare described in detail, since they are employed clinically and form the foundation for more advanced methods. These techniques can be extended to non-Cartesian sampling patterns, where the collected k-space points do not fall on a rectangular grid. Non-Cartesian acquisitions have several beneficial properties, the most important being the appearance of incoherent aliasing artifacts. Recent advances in simultaneous multi-slice imaging are presented next, which use parallel imaging to disentangle images of several slices that have been acquired at once. Parallel imaging can also be employed to accelerate 3D {MRI}, in which a contiguous volume is scanned rather than sequential slices. Another class of phase-constrained parallel imaging methods takes advantage of both image magnitude and phase to achieve better reconstruction performance. Finally, some applications are presented of parallel imaging being used to accelerate {MR} Spectroscopic Imaging.},
	pages = {71--95},
	journaltitle = {Progress in Nuclear Magnetic Resonance Spectroscopy},
	shortjournal = {Progress in Nuclear Magnetic Resonance Spectroscopy},
	author = {Hamilton, Jesse and Franson, Dominique and Seiberlich, Nicole},
	urldate = {2020-05-13},
	date = {2017-08-01},
	langid = {english},
	keywords = {Non-Cartesian, Parallel imaging, Phase-constrained, Simultaneous multi-slice, Spectroscopic imaging}
}

@article{ridgway_cardiovascular_2010,
	title = {Cardiovascular magnetic resonance physics for clinicians: part I},
	volume = {12},
	issn = {1532-429X},
	url = {https://doi.org/10.1186/1532-429X-12-71},
	doi = {10.1186/1532-429X-12-71},
	shorttitle = {Cardiovascular magnetic resonance physics for clinicians},
	abstract = {There are many excellent specialised texts and articles that describe the physical principles of cardiovascular magnetic resonance ({CMR}) techniques. There are also many texts written with the clinician in mind that provide an understandable, more general introduction to the basic physical principles of magnetic resonance ({MR}) techniques and applications. There are however very few texts or articles that attempt to provide a basic {MR} physics introduction that is tailored for clinicians using {CMR} in their daily practice. This is the first of two reviews that are intended to cover the essential aspects of {CMR} physics in a way that is understandable and relevant to this group. It begins by explaining the basic physical principles of {MR}, including a description of the main components of an {MR} imaging system and the three types of magnetic field that they generate. The origin and method of production of the {MR} signal in biological systems are explained, focusing in particular on the two tissue magnetisation relaxation properties (T1 and T2) that give rise to signal differences from tissues, showing how they can be exploited to generate image contrast for tissue characterisation. The method most commonly used to localise and encode {MR} signal echoes to form a cross sectional image is described, introducing the concept of k-space and showing how the {MR} signal data stored within it relates to properties within the reconstructed image. Before describing the {CMR} acquisition methods in detail, the basic spin echo and gradient pulse sequences are introduced, identifying the key parameters that influence image contrast, including appearances in the presence of flowing blood, resolution and image acquisition time. The main derivatives of these two pulse sequences used for cardiac imaging are then described in more detail. Two of the key requirements for {CMR} are the need for data acquisition first to be to be synchronised with the subject's {ECG} and to be fast enough for the subject to be able to hold their breath. Methods of {ECG} synchronisation using both triggering and retrospective gating approaches, and accelerated data acquisition using turbo or fast spin echo and gradient echo pulse sequences are therefore outlined in some detail. It is shown how double inversion black blood preparation combined with turbo or fast spin echo pulse sequences acquisition is used to achieve high quality anatomical imaging. For functional cardiac imaging using cine gradient echo pulse sequences two derivatives of the gradient echo pulse sequence; spoiled gradient echo and balanced steady state free precession ({bSSFP}) are compared. In each case key relevant imaging parameters and vendor-specific terms are defined and explained.},
	pages = {71},
	number = {1},
	journaltitle = {Journal of Cardiovascular Magnetic Resonance},
	shortjournal = {Journal of Cardiovascular Magnetic Resonance},
	author = {Ridgway, John P.},
	urldate = {2020-05-13},
	date = {2010-11-30}
}

@book{farooq_study_2017,
	title = {A Study On H.26x Family Of Video Streaming Compression Techniques},
	abstract = {H.264 is a standard was one made in collaboration with {ITU}-T and {ISO}/{IEC} Moving Picture Expert Group. The standard is turning out to be more prevalent as the principle objective of H.264 is to accomplish spatial versatility and to enhance the compression execution contrasted with different standards.The H.264 is utilized as a part of spatial way to encode the video, so that the size is reduced and the quantity of the frames is being decreased and it's in this way it accomplish versatility. It gives new degree to making higher quality of video encoders and also decoders that give extensive level of quality video streams at kept up bit-rates (contrasted with past standdards), or, on the other hand, a similar quality video at a lower bitrate. This paper shows an outline of the most recent video compression models identified with the H.26xfamily including its most recent standard, H.265 also called {AVC} (Advanced Video Coding)},
	author = {Farooq, Sunar and V., Dr.Madhu Viswanatham},
	date = {2017-11-28},
	doi = {10.12732/ijpam.v117i10.12}
}

@article{gurney_design_2006,
	title = {Design and analysis of a practical 3D cones trajectory},
	volume = {55},
	rights = {Copyright ¬© 2006 Wiley‚ÄêLiss, Inc.},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.20796},
	doi = {10.1002/mrm.20796},
	abstract = {The 3D Cones k-space trajectory has many desirable properties for rapid and ultra-short echo time magnetic resonance imaging. An algorithm is presented that generates the 3D Cones gradient waveforms given a desired field of view and resolution. The algorithm enables a favorable trade-off between increases in readout time and decreases in the total number of required readouts. The resulting trajectory is very signal-to-noise ratio ({SNR}) efficient and has excellent aliasing properties. A rapid high-resolution ultra-short echo time imaging sequence is used to compare the 3D Cones trajectory to 3D projection reconstruction (3DPR) sampling schemes. For equivalent scan times, the 3D Cones trajectory has better {SNR} performance and fewer aliasing artifacts as compared to the 3DPR trajectory. Magn Reson Med, 2006. ¬© 2006 Wiley-Liss, Inc.},
	pages = {575--582},
	number = {3},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Gurney, Paul T. and Hargreaves, Brian A. and Nishimura, Dwight G.},
	urldate = {2020-05-12},
	date = {2006},
	langid = {english},
	keywords = {3D Cones, non-Cartesian trajectories, rapid imaging, trajectory design, ultra-short echo time imaging}
}

@article{wu_mri_2008,
	title = {{MRI} using a concentric rings trajectory},
	volume = {59},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.21300},
	doi = {10.1002/mrm.21300},
	abstract = {The concentric rings two-dimensional (2D) k-space trajectory provides an alternative way to sample polar data. By collecting 2D k-space data in a series of rings, many unique properties are observed. The concentric rings are inherently centric-ordered, provide a smooth weighting in k-space, and enable shorter total scan times. Due to these properties, the concentric rings are well-suited as a readout trajectory for magnetization-prepared studies. When non-Cartesian trajectories are used for {MRI}, off-resonance effects can cause blurring and degrade the image quality. For the concentric rings, off-resonance blur can be corrected by retracing rings near the center of k-space to obtain a field map with no extra excitations, and then employing multifrequency reconstruction. Simulations show that the concentric rings exhibit minimal effects due to T modulation, enable shorter scan times for a Nyquist-sampled dataset than projection-reconstruction imaging or Cartesian 2D Fourier transform (2DFT) imaging, and have more spatially distributed flow and motion properties than Cartesian sampling. Experimental results show that off-resonance blurring can be successfully corrected to obtain high-resolution images. Results also show that concentric rings effectively capture the intended contrast in a magnetization-prepared sequence. Magn Reson Med, 2007. ¬© 2007 Wiley-Liss, Inc.},
	pages = {102--112},
	number = {1},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Wu, Hochong H. and Lee, Jin Hyung and Nishimura, Dwight G.},
	urldate = {2020-05-12},
	date = {2008},
	langid = {english},
	keywords = {concentric rings, magnetization preparation, non-Cartesian trajectories, off-resonance correction, polar sampling}
}

@inproceedings{blum_fast_1987,
	title = {Fast Magnetic Resonance Imaging Using Spiral Trajectories},
	volume = {0767},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/0767/0000/Fast-Magnetic-Resonance-Imaging-Using-Spiral-Trajectories/10.1117/12.966978.short},
	doi = {10.1117/12.966978},
	abstract = {Acquisition times in magnetic resonance imaging ({MRI}) are typically in the order of minutes. For an image of 256 x 256 pixels, the standard Fourier reconstruction technique used in most commercial imaging systems requires 256 separate free induction decay ({FID}) signals. While the {FID} signal itself is of relatively short duration, the successive {FID} signals are separated by long delays, of the order of seconds, to permit substantial relaxation of the signal before the next excitation. The resultant long acquisition times give rise to motion artefacts, preclude dynamic imaging and keep the patient throughput low. In this paper, we investigate a fast imaging scheme which uses spiral trajectories in the spatial frequency domain. The entire domain can be sampled in a short time, requiring as few as one {FID} acquisition. The scheme requires time varying gradients having the form of a ramped sinusoid. Several reconstruction methods are considered for forming the image from the spatial frequency domain data. The possibility of using multiple spirals to deal with the rapid decay of the {FID} signal is also examined in detail.},
	eventtitle = {Medical Imaging},
	pages = {40--46},
	booktitle = {Medical Imaging},
	publisher = {International Society for Optics and Photonics},
	author = {Blum, Mark J. and Braun, Michael and Rosenfeld, Dov},
	urldate = {2020-05-12},
	date = {1987-01-01}
}

@article{rasche_continuous_1995,
	title = {Continuous radial data acquisition for dynamic {MRI}},
	volume = {34},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.1910340515},
	doi = {10.1002/mrm.1910340515},
	abstract = {Since image acquisition times in {MRI} have been reduced considerably over recent years, several new important application areas of {MRI} have appeared. In addition to pure static anatomic information, the evolution of a dynamic process may be visualized by a sequence of temporal snapshots of the process acquired within a short time period. This makes applications like interactive or interventional {MRI} as well as the acquisition of additional functional information feasible. For high temporal resolution, all these applications require a quasi real-time image acquisition during the time the interaction or dynamic process evolves. We present an approach to realtime imaging using a continuous radial acquisition scheme. The intrinsic advantages of radial or projection reconstruction ({PR}) techniques are used to minimize motion-related image distortions. Modifications of the acquisition scheme as well as dedicated reconstruction techniques are used to further reduce the temporal blurring due to the finite acquisition time of one entire data set in our approach. So far we have used this technique for the visualization of active joint motion.},
	pages = {754--761},
	number = {5},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Rasche, Volker and Boer, Ruud W. De and Holz, Dietrich and Proksa, Roland},
	urldate = {2020-05-12},
	date = {1995},
	langid = {english},
	keywords = {fast radial imaging, fluoroscopy, projection reconstruction, real-time imaging}
}

@article{wallace_jpeg_1992,
	title = {The {JPEG} still picture compression standard},
	volume = {38},
	issn = {1558-4127},
	doi = {10.1109/30.125072},
	abstract = {A joint {ISO}/{CCITT} committee known as {JPEG} (Joint Photographic Experts Group) has been working to establish the first international compression standard for continuous-tone still images, both grayscale and color. {JPEG}'s proposed standard aims to be generic, to support a wide variety of applications for continuous-tone images. To meet the differing needs of many applications, the {JPEG} standard includes two basic compression methods, each with various modes of operation. A {DCT} (discrete cosine transform)-based method is specified for 'lossy' compression, and a predictive method for 'lossless' compression. {JPEG} features a simple lossy technique known as the Baseline method, a subset of the other {DCT}-based modes of operation. The Baseline method has been by far the most widely implemented {JPEG} method to date, and is sufficient in its own right for a large number of applications. The author provides an overview of the {JPEG} standard, and focuses in detail on the Baseline method.{\textless}{\textgreater}},
	pages = {xviii--xxxiv},
	number = {1},
	journaltitle = {{IEEE} Transactions on Consumer Electronics},
	author = {Wallace, G.K.},
	date = {1992-02},
	keywords = {Baseline method, {CCITT}, Costs, {DCT}, Digital images, Displays, Facsimile, Gray-scale, {ISO}, {ISO} standards, Image coding, Image storage, {JPEG}, Joint Photographic Experts Group, Standards development, {TV} standard, Transform coding, coding, color, continuous-tone still images, data compression, discrete cosine transform, grayscale, international compression standard, lossless compression, lossy compression, picture processing, predictive method, still picture compression standard, television standards, transforms}
}

@article{gold_musculoskeletal_2004,
	title = {Musculoskeletal {MRI} at 3.0 T: Relaxation Times and Image Contrast},
	volume = {183},
	issn = {0361-803X},
	url = {https://www.ajronline.org/doi/full/10.2214/ajr.183.2.1830343},
	doi = {10.2214/ajr.183.2.1830343},
	shorttitle = {Musculoskeletal {MRI} at 3.0 T},
	abstract = {Choose
                    Top of {pageABSTRACT} {\textless}{\textless}{IntroductionMaterials} and {MethodsResultsDiscussionReferencesCITING} {ARTICLESOBJECTIVE}. The purpose of our study was to measure relaxation times in musculoskeletal tissues at 1.5 and 3.0 T to optimize musculoskeletal {MRI} methods at 3.0 T.{MATERIALS} {AND} {METHODS}. In the knees of five healthy volunteers, we measured the T1 and T2 relaxation times of cartilage, synovial fluid, muscle, marrow, and fat at 1.5 and 3.0 T. The T1 relaxation times were measured using a spiral Look-Locker sequence with eight samples along the T1 recovery curve. The T2 relaxation times were measured using a spiral T2 preparation sequence with six echoes. Accuracy and repeatability of the T1 and T2 measurement sequences were verified in phantoms.{RESULTS}. T1 relaxation times in cartilage, muscle, synovial fluid, marrow, and subcutaneous fat at 3.0 T were consistently higher than those measured at 1.5 T. Measured T2 relaxation times were reduced at 3.0 T compared with 1.5 T. Relaxation time measurements in vivo were verified using calculated and measured signal-to-noise results. Relaxation times were used to develop a high-resolution protocol for T2-weighted imaging of the knee at 3.0 T.{CONCLUSION}. {MRI} at 3.0 T can improve resolution and speed in musculoskeletal imaging; however, interactions between field strength and relaxation times need to be considered for optimal image contrast and signal-to-noise ratio. Scanning can be performed in shorter times at 3.0 T using single-average acquisitions. Efficient higher-resolution imaging at 3.0 T can be done by increasing the {TR} to account for increased T1 relaxation times and acquiring thinner slices than at 1.5 T.},
	pages = {343--351},
	number = {2},
	journaltitle = {American Journal of Roentgenology},
	shortjournal = {American Journal of Roentgenology},
	author = {Gold, Garry E. and Han, Eric and Stainsby, Jeff and Wright, Graham and Brittain, Jean and Beaulieu, Christopher},
	urldate = {2020-05-12},
	date = {2004-08-01}
}

@article{bojorquez_what_2017,
	title = {What are normal relaxation times of tissues at 3 T?},
	abstract = {The T1 and T2 relaxation times are the basic parameters behind magnetic resonance imaging. The accurate knowledge of the T1 and T2 values of tissues allows to perform quantitative imaging and to develop and optimize magnetic resonance sequences. A vast extent of methods and sequences has been developed to calculate the T1 and T2 relaxation times of different tissues in diverse centers. Surprisingly, a wide range of values has been reported for similar tissues (e.g. T1 of white matter from 699 to 1735 ms and T2 of fat from 41 to 371 ms), and the true values that represent each speciÔ¨Åc tissue are still unclear, which have deterred their common use in clinical diagnostic imaging. This article presents a comprehensive review of the reported relaxation times in the literature in vivo at 3 T for a large span of tissues. It gives a detailed analysis of the different methods and sequences used to calculate the relaxation times, and it explains the reasons of the spread of reported relaxation times values in the literature.},
	pages = {12},
	journaltitle = {Magnetic Resonance Imaging},
	author = {Bojorquez, Jorge Zavala and Bricq, St√©phanie and Acquitter, Clement and Brunotte, Fran√ßois and Walker, Paul M and Lalande, Alain},
	date = {2017},
	langid = {english}
}

@article{stanisz_t1_nodate,
	title = {T1, T2 relaxation and magnetization transfer in tissue at 3T},
	pages = {6},
	author = {Stanisz, Greg J and Odrobina, Ewa E and Pun, Joseph and Escaravage, Michael and Graham, Simon J and Bronskill, Michael J and Henkelman, R Mark},
	langid = {english}
}

@article{dong_compressive_2014,
	title = {Compressive Sensing via Nonlocal Low-Rank Regularization},
	volume = {23},
	issn = {1941-0042},
	doi = {10.1109/TIP.2014.2329449},
	abstract = {Sparsity has been widely exploited for exact reconstruction of a signal from a small number of random measurements. Recent advances have suggested that structured or group sparsity often leads to more powerful signal reconstruction techniques in various compressed sensing ({CS}) studies. In this paper, we propose a nonlocal low-rank regularization ({NLR}) approach toward exploiting structured sparsity and explore its application into {CS} of both photographic and {MRI} images. We also propose the use of a nonconvex log det ( X) as a smooth surrogate function for the rank instead of the convex nuclear norm and justify the benefit of such a strategy using extensive experiments. To further improve the computational efficiency of the proposed algorithm, we have developed a fast implementation using the alternative direction multiplier method technique. Experimental results have shown that the proposed {NLR}-{CS} algorithm can significantly outperform existing state-of-the-art {CS} techniques for image recovery.},
	pages = {3618--3632},
	number = {8},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Dong, Weisheng and Shi, Guangming and Li, Xin and Ma, Yi and Huang, Feng},
	date = {2014-08},
	keywords = {Algorithms, Approximation methods, Brain, Compresses sensing, Data Compression, Educational institutions, Fourier transforms, Humans, Image Enhancement, Image Interpretation, Computer-Assisted, Image reconstruction, {MRI} images, Magnetic Resonance Imaging, Magnetic resonance imaging, Minimization, {NLR}-{CS} algorithm, Optimization, Pattern Recognition, Automated, Reproducibility of Results, Sample Size, Sensitivity and Specificity, Signal Processing, Computer-Assisted, alternative direction multiplier method, biomedical {MRI}, compressed sensing, compressive sensing, concave programming, convex nuclear norm, convex programming, group sparsity, image reconstruction, image recovery, low-rank approximation, medical image processing, nonconvex log det(X), nonconvex optimization, nonlocal low-rank regularization, photographic image, photography, random measurement, signal reconstruction, smooth surrogate function, smoothing methods, structured sparsity}
}
@article{ongie_fast_2017,
	title = {A Fast Algorithm for Convolutional Structured Low-Rank Matrix Recovery},
	volume = {3},
	issn = {2333-9403},
	doi = {10.1109/TCI.2017.2721819},
	abstract = {Fourier-domain structured low-rank matrix priors are emerging as powerful alternatives to traditional image recovery methods such as total variation and wavelet regularization. These priors specify that a convolutional structured matrix, i.e., Toeplitz, Hankel, or their multilevel generalizations, built from Fourier data of the image should be low-rank. The main challenge in applying these schemes to large-scale problems is the computational complexity and memory demand resulting from lifting the image data to a large-scale matrix. We introduce a fast and memory-efficient approach called the generic iterative reweighted annihilation filter algorithm that exploits the convolutional structure of the lifted matrix to work in the original unlifted domain, thus considerably reducing the complexity. Our experiments on the recovery of images from undersampled Fourier measurements show that the resulting algorithm is considerably faster than previously proposed algorithms and can accommodate much larger problem sizes than previously studied.},
	pages = {535--550},
	number = {4},
	journaltitle = {{IEEE} Transactions on Computational Imaging},
	author = {Ongie, Gregory and Jacob, Mathews},
	date = {2017-12},
	keywords = {Annihilating filter, Approximation algorithms, Convolution, Fourier analysis, Fourier measurements, Fourier-domain structured low-rank matrix, Image reconstruction, Jacobian matrices, {MRI} reconstruction, Magnetic resonance imaging, Transmission line matrix methods, compressed sensing, computational complexity, convolution, convolutional structure, finite rate of innovation, image data, image filtering, image reconstruction, image recovery, iterative methods, iterative reweighted annihilation filter algorithm, large-scale matrix, low-rank matrix recovery, matrix algebra, multi-level Toeplitz matrices, structured low-rank matrix recovery}
}

@article{majumdar_non-convex_2013,
	title = {Non-convex algorithm for sparse and low-rank recovery: Application to dynamic {MRI} reconstruction},
	volume = {31},
	issn = {0730-725X},
	url = {http://www.sciencedirect.com/science/article/pii/S0730725X12003220},
	doi = {10.1016/j.mri.2012.08.011},
	shorttitle = {Non-convex algorithm for sparse and low-rank recovery},
	abstract = {In this work we exploit two assumed properties of dynamic {MRI} in order to reconstruct the images from under-sampled K-space samples. The first property assumes the signal is sparse in the x-f space and the second property assumes the signal is rank-deficient in the x-t space. These assumptions lead to an optimization problem that requires minimizing a combined lp-norm and Schatten-p norm. We propose a novel {FOCUSS} based approach to solve the optimization problem. Our proposed method is compared with state-of-the-art techniques in dynamic {MRI} reconstruction. Experimental evaluation carried out on three real datasets shows that for all these datasets, our method yields better reconstruction both in quantitative and qualitative evaluation.},
	pages = {448--455},
	number = {3},
	journaltitle = {Magnetic Resonance Imaging},
	shortjournal = {Magnetic Resonance Imaging},
	author = {Majumdar, Angshul and Ward, Rabab K. and Aboulnasr, Tyseer},
	urldate = {2020-05-12},
	date = {2013-04-01},
	langid = {english},
	keywords = {Compressed Sensing, Low-rank matrix completion, Offline dynamic {MRI} reconstruction, Sparse recovery}
}

@online{noauthor_newsletter_2019,
	title = {Newsletter January 2019},
	url = {https://juliacomputing.com/blog/2019/01/04/january-newsletter.html},
	abstract = {Julia Computing was founded with a mission to make Julia easy to use, easy to deploy and easy to scale. We operate out of Boston, London and Bangalore and we serve customers worldwide.},
	titleaddon = {juliacomputing.com},
	urldate = {2020-05-11},
	date = {2019-01-04}
}

@online{noauthor_why_2018,
	title = {Why Numba and Cython are not substitutes for Julia},
	url = {https://www.stochasticlifestyle.com/why-numba-and-cython-are-not-substitutes-for-julia/},
	abstract = {Sometimes people ask: why does Julia need to be a new language? What about Julia is truly different from tools like Cython and Numba? The purpose of this blog post is to describe how Julia's design gives a very different package development experience than something like Cython, and how that can lead to many more optimizations. What I really want to show is: Julia's compilation setup is built for specialization of labor which is required for scientific progress Composition of Julia codes can utilize the compilation process to build new programs which are greater than the sum of the parts I will also explain some of the engineering tradeoffs which were made to make this happen. There are many state-of-the-art scientific computing and data science packages in Julia and what I want to describe is how these are using the more "hardcore ... {READ} {MORE}},
	titleaddon = {Stochastic Lifestyle},
	urldate = {2020-05-11},
	date = {2018-08-06},
	langid = {american}
}

@book{nishimura_principles_1996,
	title = {Principles of magnetic resonance imaging},
	pagetotal = {232},
	publisher = {Stanford University},
	author = {Nishimura, Dwight George},
	date = {1996},
	note = {Google-Books-{ID}: uz9BAQAAIAAJ},
	keywords = {Magnetic resonance imaging, Medical / Diagnostic Imaging, Medical / Radiology \& Nuclear Medicine, Technology \& Engineering / Imaging Systems}
}

@article{pooley_fundamental_2005,
	title = {Fundamental Physics of {MR} Imaging},
	volume = {25},
	issn = {0271-5333},
	url = {https://pubs.rsna.org/doi/full/10.1148/rg.254055027},
	doi = {10.1148/rg.254055027},
	abstract = {Learning the basic concepts required to understand magnetic resonance ({MR}) imaging is a straightforward process. Although the individual concepts are simple, there are many concepts to learn and retain simultaneously; this situation may give the illusion that learning the physics of {MR} imaging is complicated. It is important for the radiologist who interprets {MR} images to understand the methods used to create the images because image contrast specifically depends on how the image data were acquired. Initial concepts include formation of magnetic fields from electric currents in loops of wire, the resonance phenomenon, the hydrogen proton and its frequency of precession, and absorption of radiofrequency energy. These concepts can then be applied to learn about T1 and T2 relaxation and contrast and how the acquisition parameters of echo time and repetition time can be used to achieve these image contrasts. Basic pulse sequences include the spin-echo, multiecho spin-echo, turbo spin-echo, inversion-recovery, and gradient-recalled-echo sequences.¬© {RSNA}, 2005},
	pages = {1087--1099},
	number = {4},
	journaltitle = {{RadioGraphics}},
	shortjournal = {{RadioGraphics}},
	author = {Pooley, Robert A.},
	urldate = {2020-05-10},
	date = {2005-07-01}
}

@thesis{kurzhunov_novel_2017,
	title = {Novel Reconstruction and Quantification Methods for Oxygen-17 Magnetic Resonance Imaging at Clinical Field Strengths},
	url = {https://www.researchgate.net/publication/318658798_Novel_Reconstruction_and_Quantification_Methods_for_Oxygen-17_Magnetic_Resonance_Imaging_at_Clinical_Field_Strengths},
	type = {phdthesis},
	author = {Kurzhunov, Dmitry},
	urldate = {2020-05-10},
	date = {2017-09},
	doi = {10.13140/RG.2.2.22003.02089}
}

@article{kwong_dynamic_1992,
	title = {Dynamic magnetic resonance imaging of human brain activity during primary sensory stimulation.},
	volume = {89},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/89/12/5675},
	doi = {10.1073/pnas.89.12.5675},
	abstract = {Neuronal activity causes local changes in cerebral blood flow, blood volume, and blood oxygenation. Magnetic resonance imaging ({MRI}) techniques sensitive to changes in cerebral blood flow and blood oxygenation were developed by high-speed echo planar imaging. These techniques were used to obtain completely noninvasive tomographic maps of human brain activity, by using visual and motor stimulus paradigms. Changes in blood oxygenation were detected by using a gradient echo ({GE}) imaging sequence sensitive to the paramagnetic state of deoxygenated hemoglobin. Blood flow changes were evaluated by a spin-echo inversion recovery ({IR}), tissue relaxation parameter T1-sensitive pulse sequence. A series of images were acquired continuously with the same imaging pulse sequence (either {GE} or {IR}) during task activation. Cine display of subtraction images (activated minus baseline) directly demonstrates activity-induced changes in brain {MR} signal observed at a temporal resolution of seconds. During 8-Hz patterned-flash photic stimulation, a significant increase in signal intensity (paired t test; P less than 0.001) of 1.8\% +/- 0.8\% ({GE}) and 1.8\% +/- 0.9\% ({IR}) was observed in the primary visual cortex (V1) of seven normal volunteers. The mean rise-time constant of the signal change was 4.4 +/- 2.2 s for the {GE} images and 8.9 +/- 2.8 s for the {IR} images. The stimulation frequency dependence of visual activation agrees with previous positron emission tomography observations, with the largest {MR} signal response occurring at 8 Hz. Similar signal changes were observed within the human primary motor cortex (M1) during a hand squeezing task and in animal models of increased blood flow by hypercapnia. By using intrinsic blood-tissue contrast, functional {MRI} opens a spatial-temporal window onto individual brain physiology.},
	pages = {5675--5679},
	number = {12},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Kwong, K. K. and Belliveau, J. W. and Chesler, D. A. and Goldberg, I. E. and Weisskoff, R. M. and Poncelet, B. P. and Kennedy, D. N. and Hoppel, B. E. and Cohen, M. S. and Turner, R.},
	urldate = {2020-05-10},
	date = {1992-06-15},
	langid = {english},
	pmid = {1608978}
}

@article{ogawa_brain_1990,
	title = {Brain magnetic resonance imaging with contrast dependent on blood oxygenation},
	volume = {87},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/87/24/9868},
	doi = {10.1073/pnas.87.24.9868},
	abstract = {Paramagnetic deoxyhemoglobin in venous blood is a naturally occurring contrast agent for magnetic resonance imaging ({MRI}). By accentuating the effects of this agent through the use of gradient-echo techniques in high fields, we demonstrate in vivo images of brain microvasculature with image contrast reflecting the blood oxygen level. This blood oxygenation level-dependent ({BOLD}) contrast follows blood oxygen changes induced by anesthetics, by insulin-induced hypoglycemia, and by inhaled gas mixtures that alter metabolic demand or blood flow. The results suggest that {BOLD} contrast can be used to provide in vivo real-time maps of blood oxygenation in the brain under normal physiological conditions. {BOLD} contrast adds an additional feature to magnetic resonance imaging and complements other techniques that are attempting to provide positron emission tomography-like measurements related to regional neural activity.},
	pages = {9868--9872},
	number = {24},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Ogawa, S. and Lee, T. M. and Kay, A. R. and Tank, D. W.},
	urldate = {2020-05-10},
	date = {1990-12-01},
	langid = {english},
	pmid = {2124706}
}

@article{barbier_methodology_2001,
	title = {Methodology of brain perfusion imaging},
	volume = {13},
	rights = {Copyright ¬© 2001 Wiley‚ÄêLiss, Inc.},
	issn = {1522-2586},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.1073},
	doi = {10.1002/jmri.1073},
	abstract = {Numerous techniques have been proposed in the last 15 years to measure various perfusion-related parameters in the brain. In particular, two approaches have proven extremely successful: injection of paramagnetic contrast agents for measuring cerebral blood volumes ({CBV}) and arterial spin labeling ({ASL}) for measuring cerebral blood flows ({CBF}). This review presents the methodology of the different magnetic resonance imaging ({MRI}) techniques in use for {CBV} and {CBF} measurements and briefly discusses their limitations and potentials. J. Magn. Reson. Imaging 2001;13:496‚Äì520. ¬© 2001 Wiley-Liss, Inc.},
	pages = {496--520},
	number = {4},
	journaltitle = {Journal of Magnetic Resonance Imaging},
	author = {Barbier, Emmanuel L. and Lamalle, Laurent and D√©corps, Michel},
	urldate = {2020-05-10},
	date = {2001},
	langid = {english},
	keywords = {arterial spin labeling, arterial spin tagging, bolus tracking, cerebral blood flow, cerebral blood volume, contrast agent, dynamic susceptibility contrast, functional imaging, magnetic resonance imaging, mean transit time, neuroimaging, review, transit time}
}

@article{rosen_perfusion_1990,
	title = {Perfusion imaging with {NMR} contrast agents},
	volume = {14},
	rights = {Copyright ¬© 1990 Wiley‚ÄêLiss, Inc., A Wiley Company},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.1910140211},
	doi = {10.1002/mrm.1910140211},
	abstract = {Knowledge of regional hemodynamics has widespread application for both physiological research and clinical assessment. Here we review the use of {MR} contrast agents to measure tissue perfusion. Two primary mechanisms of image contrast are discussed: relaxivity and susceptibility effects. Relaxivity effects result from dipolar enhancement of T1 and T2 rates. Because tissue T1 rates are intrinsically smaller, the dominant effect is shortening of T1 relaxation times. The second mechanism of image contrast is the variation in tissue magnetic field produced by heterogeneous distribution of high magnetic susceptibility agents. Quantitation of tissue perfusion requires a detailed understanding of the relation between contrast agent concentration and associated {MR} signal changes. Studies to date show a linear relationship between contrast agent concentration and rate change in most organs. The exact nature of this relationship in the dynamic setting of rapid contrast agent passage through the microcirculatory bed is less well established. If this relationship is known, tracer kinetic modeling can be used to calculate regional blood flow and blood volume. Data are presented which indicate that this approach is feasible, and suggest the potential of contrast-enhanced {NMR} for high resolution in vivo mapping of both physiology and anatomy. ¬© 1990 Academic Press, Inc.},
	pages = {249--265},
	number = {2},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Rosen, Bruce R. and Belliveau, John W. and Vevea, James M. and Brady, Thomas J.},
	urldate = {2020-05-10},
	date = {1990},
	langid = {english}
}

@article{detre_perfusion_1992,
	title = {Perfusion imaging},
	volume = {23},
	rights = {Copyright ¬© 1992 Wiley‚ÄêLiss, Inc., A Wiley Company},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.1910230106},
	doi = {10.1002/mrm.1910230106},
	abstract = {Measurement of tissue perfusion is important for the functional assessment of organs in vivo. Here we report the use of 1H {NMR} imaging to generate perfusion maps in the rat brain at 4.7 T. Blood water flowing to the brain is saturated in the neck region with a sliceselective saturation imaging sequence, creating an endogenous tracer in the form of proximally saturated spins. Because proton T1 times are relatively long, particularly at high field strengths, saturated spins exchange with bulk water in the brain and a steady state is created where the regional concentration of saturated spins is determined by the regional blood flow and regional T1. Distal saturation applied equidistantly outside the brain serves as a control for effects of the saturation pulses. Average cerebral blood flow in normocapnic rat brain under halothane anesthesia was determined to be 105 ¬± 16 cc. 100 g‚àí1. min‚àí1 (mean ¬± {SEM}, n = 3), in good agreement with values reported in the literature, and was sensitive to increases in arterial {pCO}2. This technique allows regional perfusion maps to be measured noninvasively, with the resolution of 1H {MRI}, and should be readily applicable to human studies. ¬© 1992 Academic Press, Inc.},
	pages = {37--45},
	number = {1},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Detre, John A. and Leigh, John S. and Williams, Donald S. and Koretsky, Alan P.},
	urldate = {2020-05-10},
	date = {1992},
	langid = {english}
}

@article{moseley_diffusion-weighted_1990,
	title = {Diffusion-weighted {MR} imaging of anisotropic water diffusion in cat central nervous system.},
	volume = {176},
	issn = {0033-8419},
	url = {https://pubs.rsna.org/doi/abs/10.1148/radiology.176.2.2367658},
	doi = {10.1148/radiology.176.2.2367658},
	abstract = {The diffusion behavior of intracranial water in the cat brain and spine was examined with the use of diffusion-weighted magnetic resonance ({MR}) imaging, in which the direction of the diffusion-sensitizing gradient was varied between the x, y, and z axes of the magnet. At very high diffusion-sensitizing gradient strengths, no clear evidence of anisotropic water diffusion was found in either cortical or subcortical (basal ganglia) gray matter. Signal intensities clearly dependent on orientation were observed in the cortical and deep white matter of the brain and in the white matter of the spinal cord. Greater signal attenuation (faster diffusion) was observed when the relative orientation of white matter tracts to the diffusion-sensitizing gradient was parallel as compared to that obtained with a perpendicular alignment. These effects were seen on both premortem and immediate postmortem images obtained in all axial, sagittal, and coronal views. Potential applications of this {MR} imaging technique included the stereospecific evaluation of white matter in the brain and spinal cord and in the characterization of demyelinating and dysmyelinating diseases.},
	pages = {439--445},
	number = {2},
	journaltitle = {Radiology},
	shortjournal = {Radiology},
	author = {Moseley, M E and Cohen, Y and Kucharczyk, J and Mintorovitch, J and Asgari, H S and Wendland, M F and Tsuruda, J and Norman, D},
	urldate = {2020-05-10},
	date = {1990-08-01}
}

@article{bammer_basic_2003,
	title = {Basic principles of diffusion-weighted imaging},
	volume = {45},
	issn = {0720-048X},
	url = {http://www.sciencedirect.com/science/article/pii/S0720048X02003030},
	doi = {10.1016/S0720-048X(02)00303-0},
	abstract = {In diffusion-weighted {MRI} ({DWI}), image contrast is determined by the random microscopic motion of water protons. During the last years, {DWI} has become an important modality in the diagnostic work-up of acute ischemia in the {CNS}. There are also a few promising reports about the application of {DWI} to other regions in the human body, such as the vertebral column or the abdomen. This manuscript provides an introduction into the basics of {DWI} and Diffusion Tensor imaging. The potential of various {MR} sequences in concert with diffusion preparation are discussed with respect to acquisition speed, spatial resolution, and sensitivity to bulk physiologic motion. More advanced diffusion measurement techniques, such as high angular resolution diffusion imaging, are also addressed.},
	pages = {169--184},
	number = {3},
	journaltitle = {European Journal of Radiology},
	shortjournal = {European Journal of Radiology},
	author = {Bammer, Roland},
	urldate = {2020-05-10},
	date = {2003-03-01},
	langid = {english},
	keywords = {Diffusion, {MRI}, Magnetic resonance imaging, Tensor}
}

@article{bedell_implementation_1998,
	title = {Implementation and evaluation of a new pulse sequence for rapid acquisition of double inversion recovery images for simultaneous suppression of white matter and {CSF}},
	volume = {8},
	rights = {Copyright ¬© 1998 Wiley‚ÄêLiss, Inc., A Wiley Company},
	issn = {1522-2586},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.1880080305},
	doi = {10.1002/jmri.1880080305},
	abstract = {We describe a fast double inversion recovery ({DIR}) imaging sequence that effectively attenuates signal from both white matter and cerebrospinal fluid ({CSF}). The pulse sequence uses a novel inversion/excitation scheme and fast spin-echo readout to maximize scan efficiency. The white matter/{CSF} suppressed images can be acquired from the entire brain in ‚àº6 minutes. Evaluation of the fast {DIR} sequence on patients with multiple sclerosis ({MS}) demonstrates high lesion conspicuity.},
	pages = {544--547},
	number = {3},
	journaltitle = {Journal of Magnetic Resonance Imaging},
	author = {Bedell, Barry J. and Narayana, Ponnada A.},
	urldate = {2020-05-10},
	date = {1998},
	langid = {english},
	keywords = {Brain, Double inversion recovery, Magnetic resonance imaging, Multiple sclerosis}
}

@article{ashgriz_flair_1991,
	title = {{FLAIR}: Flux line-segment model for advection and interface reconstruction},
	volume = {93},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/002199919190194P},
	doi = {10.1016/0021-9991(91)90194-P},
	shorttitle = {{FLAIR}},
	abstract = {A computational technique for solving fluid problems with free surfaces and interfaces is presented. The conventional cell volume fraction approach is employed for tracking the interfaces. However, for surface advection and its reconstruction, a new and more accurate {FLAIR} (flux line-segment model for advection and interface reconstruction) algorithm is developed. The surface is approximated by a set of line segments fitted at the boundary of every two neighboring computational cells. A criterion is developed for identifying the line-segment orientation by inspecting the cell volume fractions. The new cell volume fraction field is obtained by integrating the advected area underneath the interface line-segment. As an example, this technique is applied to the capillary driven viscous flow of an initially elliptic, two-dimensional fluid zone. The problem is posed mathematically as a solution of the Navier-Stokes equations with moving free surface boundary conditions. The damping motion of the fluid zone is observed through transport of the free surface, which is related to the instantaneous internal velocity field under the influence of surface tension and viscous forces.},
	pages = {449--468},
	number = {2},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Ashgriz, N and Poo, J. Y},
	urldate = {2020-05-10},
	date = {1991-04-01},
	langid = {english}
}

@article{fleckenstein_fast_1991,
	title = {Fast short-tau inversion-recovery {MR} imaging.},
	volume = {179},
	issn = {0033-8419},
	url = {https://pubs.rsna.org/doi/abs/10.1148/radiology.179.2.2014300},
	doi = {10.1148/radiology.179.2.2014300},
	abstract = {To enhance the versatility of the short-tau inversion-recovery ({STIR}) sequences, the authors determined a range of repetition time ({TR}) and inversion time ({TI}) combinations that suppress signal intensity from fat by study of both patient and phantom images. To make fast {STIR} images, variations in the following pulsing conditions were studied with use of an interactive computer program: decreasing the {TR}, limiting the number of excitations, and limiting the number of phase-encoding steps. The authors found that (a) {STIR} imaging need not be time consuming, (b) fat suppression can be accomplished at shorter {TR} by using shorter {TI}, and (c) short-{TR} fast {STIR} imaging is sensitive to enhancement with gadopentetate dimeglumine.},
	pages = {499--504},
	number = {2},
	journaltitle = {Radiology},
	shortjournal = {Radiology},
	author = {Fleckenstein, J L and Archer, B T and Barker, B A and Vaughan, J T and Parkey, R W and Peshock, R M},
	urldate = {2020-05-10},
	date = {1991-05-01}
}

@article{dwyer_short-ti_1988,
	title = {Short-Ti inversion-recovery pulse sequence: analysis and initial experience in cancer imaging.},
	volume = {168},
	issn = {0033-8419},
	url = {https://pubs.rsna.org/doi/abs/10.1148/radiology.168.3.3406412},
	doi = {10.1148/radiology.168.3.3406412},
	shorttitle = {Short-Ti inversion-recovery pulse sequence},
	abstract = {Inversion recovery ({IR}), commonly considered a pulse sequence capable of producing T1-weighted images with excellent display of normal anatomy, is versatile: The null point and peak time provide a useful, succinct summary of the properties of {IR} and its capacity for producing both T1- and T2-weighted images. Shortening of the inversion time ({TI}) and creation of a short-{TI} inversion-recovery ({STIR}) pulse sequence increases sensitivity to malignancy and other abnormalities by making the effects of prolonged T1 and T2 on signal intensity additive and by nulling the signal from fat. The authors examined over 300 patients with various malignancies and compared {STIR} images with T1- and T2-weighted images obtained at 0.5 T. In 43 cases, signal-difference-to-noise ratios ({SD}/Ns) were calculated between tumor, fat, and muscle. In general, {STIR} images demonstrated tumor as a conspicuously high-intensity area in a background of muted, discernible anatomic detail. The good contrast achieved with {STIR} sequences between tumor and fat ({SD}/N = 18.1) and tumor and muscle ({SD}/N = 12.9) consolidated into a single image the information contained separately on T1- and T2-weighted images, which facilitates efficient detection and localization of malignancy.},
	pages = {827--836},
	number = {3},
	journaltitle = {Radiology},
	shortjournal = {Radiology},
	author = {Dwyer, A J and Frank, J A and Sank, V J and Reinig, J W and Hickey, A M and Doppman, J L},
	urldate = {2020-05-10},
	date = {1988-09-01}
}

@article{winkler_characteristics_1988,
	title = {Characteristics of partial flip angle and gradient reversal {MR} imaging.},
	volume = {166},
	issn = {0033-8419},
	url = {https://pubs.rsna.org/doi/abs/10.1148/radiology.166.1.3275967},
	doi = {10.1148/radiology.166.1.3275967},
	pages = {17--26},
	number = {1},
	journaltitle = {Radiology},
	shortjournal = {Radiology},
	author = {Winkler, M L and Ortendahl, D A and Mills, T C and Crooks, L E and Sheldon, P E and Kaufman, L and Kramer, D M},
	urldate = {2020-05-10},
	date = {1988-01-01}
}

@article{hahn_spin_1950,
	title = {Spin Echoes},
	volume = {80},
	url = {https://link.aps.org/doi/10.1103/PhysRev.80.580},
	doi = {10.1103/PhysRev.80.580},
	abstract = {Intense radiofrequency power in the form of pulses is applied to an ensemble of spins in a liquid placed in a large static magnetic field H0. The frequency of the pulsed r-f power satisfies the condition for nuclear magnetic resonance, and the pulses last for times which are short compared with the time in which the nutating macroscopic magnetic moment of the entire spin ensemble can decay. After removal of the pulses a non-equilibrium configuration of isochromatic macroscopic moments remains in which the moment vectors precess freely. Each moment vector has a magnitude at a given precession frequency which is determined by the distribution of Larmor frequencies imposed upon the ensemble by inhomogeneities in H0. At times determined by pulse sequences applied in the past the constructive interference of these moment vectors gives rise to observable spontaneous nuclear induction signals. The properties and underlying principles of these spin echo signals are discussed with use of the Bloch theory. Relaxation times are measured directly and accurately from the measurement of echo amplitudes. An analysis includes the effect on relaxation measurements of the self-diffusion of liquid molecules which contain resonant nuclei. Preliminary studies are made of several effects associated with spin echoes, including the observed shifts in magnetic resonance frequency of spins due to magnetic shielding of nuclei contained in molecules.},
	pages = {580--594},
	number = {4},
	journaltitle = {Physical Review},
	shortjournal = {Phys. Rev.},
	author = {Hahn, E. L.},
	urldate = {2020-05-09},
	date = {1950-11-15}
}

@online{coyne_mri_2020,
	title = {{MRI}: A Guided Tour - {MagLab}},
	url = {https://nationalmaglab.org/education/magnet-academy/learn-the-basics/stories/mri-a-guided-tour},
	shorttitle = {{MRI}},
	abstract = {These awesome diagnostic tools, powered by strong superconducting magnets, save countless lives with their ability to pinpoint tumors and other abnormalities.},
	titleaddon = {Magnet Academy},
	author = {Coyne, Kristen},
	urldate = {2020-05-08},
	date = {2020-04-06},
	langid = {british}
}

@article{ladd_pros_2018,
	title = {Pros and cons of ultra-high-field {MRI}/{MRS} for human application},
	volume = {109},
	issn = {0079-6565},
	url = {http://www.sciencedirect.com/science/article/pii/S007965651830013X},
	doi = {10.1016/j.pnmrs.2018.06.001},
	abstract = {Magnetic resonance imaging and spectroscopic techniques are widely used in humans both for clinical diagnostic applications and in basic research areas such as cognitive neuroimaging. In recent years, new human {MR} systems have become available operating at static magnetic fields of 7‚ÄØT or higher (‚â•300‚ÄØ{MHz} proton frequency). Imaging human-sized objects at such high frequencies presents several challenges including non-uniform radiofrequency fields, enhanced susceptibility artifacts, and higher radiofrequency energy deposition in the tissue. On the other side of the scale are gains in signal-to-noise or contrast-to-noise ratio that allow finer structures to be visualized and smaller physiological effects to be detected. This review presents an overview of some of the latest methodological developments in human ultra-high field {MRI}/{MRS} as well as associated clinical and scientific applications. Emphasis is given to techniques that particularly benefit from the changing physical characteristics at high magnetic fields, including susceptibility-weighted imaging and phase-contrast techniques, imaging with X-nuclei, {MR} spectroscopy, {CEST} imaging, as well as functional {MRI}. In addition, more general methodological developments such as parallel transmission and motion correction will be discussed that are required to leverage the full potential of higher magnetic fields, and an overview of relevant physiological considerations of human high magnetic field exposure is provided.},
	pages = {1--50},
	journaltitle = {Progress in Nuclear Magnetic Resonance Spectroscopy},
	shortjournal = {Progress in Nuclear Magnetic Resonance Spectroscopy},
	author = {Ladd, Mark E. and Bachert, Peter and Meyerspeer, Martin and Moser, Ewald and Nagel, Armin M. and Norris, David G. and Schmitter, Sebastian and Speck, Oliver and Straub, Sina and Zaiss, Moritz},
	urldate = {2020-05-08},
	date = {2018-12-01},
	langid = {english},
	keywords = {7‚ÄØTesla, Human, {MRI}, {MRS}, Ultra-high field}
}

@article{schepkin_vivo_2012,
	title = {In vivo magnetic resonance imaging of sodium and diffusion in rat glioma at 21.1 T},
	volume = {67},
	rights = {Copyright ¬© 2011 Wiley‚ÄêLiss, Inc.},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.23077},
	doi = {10.1002/mrm.23077},
	abstract = {Sodium and diffusion magnetic resonance imaging ({MRI}) in intracranial rat 9L gliomas were evaluated over 6‚Äì8 days using the advanced sensitivity of sodium {MRI} at 21.1 T. Glioma doubling time was 2.4‚Äì2.6 days. Glioma sodium signal was detected using the ultra-short echo time of 0.15 ms. The high resolution 3D sodium {MRI} with pixels of 0.125 ŒºL allowed for minimizing a partial volume effect often relevant to the {MRI} of low intensity signals. Tumor sodium and diffusion {MRI} were evaluated for two separate subclones of 9L cells with different resistance to 1,3-bis(2-chloroethyl)-1-nitrosurea detected by pre-surgery assays. In vivo, after implantation, resistant 9L cells created tumors with significantly reduced sodium concentrations (57 ¬± 3 {mM}) compared with nonresistant 9L cells (78 ¬± 3 {mM}). The corresponding differences in diffusion were less, but also statistically significant. During tumor progression, an increase of glioma sodium concentration was observed in both cell types with a rate of 2.4‚Äì5.8 \%/day relative to normal brain. Tumor diffusion was not significantly changed at this time, indicative of no alterations in glioma cellularity. Thus, changes in sodium during tumor progression reflect increasing intracellular sodium concentration and mounting metabolic stress. These experiments also demonstrate an enhanced sensitivity of sodium {MRI} to reflect tumor cell resistance. Magn Reson Med, 2011. ¬© 2011 Wiley-Liss, Inc.},
	pages = {1159--1166},
	number = {4},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Schepkin, Victor D. and Bejarano, Fabian Calixto and Morgan, Thomas and Gower‚ÄêWinter, Shannon and Ozambela, Manuel and Levenson, Cathy W.},
	urldate = {2020-05-08},
	date = {2012},
	langid = {english},
	keywords = {{MRI}, diffusion, glioma resistance, sodium, ultra high magnetic field}
}

@article{richmond_sir_2004,
	title = {Sir Godfrey Hounsfield},
	volume = {329},
	issn = {0959-8138},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC517662/},
	doi = {10.1136/bmj.329.7467.687},
	abstract = {Engineer who invented computed tomography and won the Nobel prize for medicine},
	pages = {687},
	number = {7467},
	journaltitle = {{BMJ} : British Medical Journal},
	shortjournal = {{BMJ}},
	author = {Richmond, Caroline},
	date = {2004-09-18},
	pmid = {null},
	pmcid = {PMC517662}
}

@online{noauthor_us_nodate,
	title = {U.S. {DOE} Molecular Nuclear Medicine Timeline},
	url = {https://www.doemedicalsciences.org/timeline.shtml},
	urldate = {2020-05-08}
}

@article{griffiths_historical_nodate,
	title = {An historical look at ultrasound as an Australian innovation on the occasion of the ultrasound stamp issued by Australia Post ‚Äì 18 May 2004},
	pages = {5},
	author = {Griffiths, Kaye A},
	langid = {english}
}

@article{rinck_short_2008,
	title = {A short history of magnetic resonance imaging},
	volume = {20},
	pages = {3},
	number = {1},
	author = {Rinck, Peter A},
	date = {2008},
	langid = {english}
}

@article{singh_origin_2007,
	title = {The Origin of Echocardiography},
	volume = {34},
	issn = {0730-2347},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2170493/},
	abstract = {The original description of M-mode echocardiography in 1953, by Inge Edler (1911‚Äì2001) and his physicist friend Hellmuth Hertz, marked the beginning of a new diagnostic noninvasive technique. Edler used this technique primarily for the preoperative study of mitral stenosis and diagnosis of mitral regurgitation. His work was carried forward by cardiologists all over the world, who developed Doppler, 2-dimensional, contrast, and transesophageal echocardiography. These are now standard in cardiologic examinations. Edler also influenced neurologists and obstetricians at Lund University (Sweden) to use ultrasound in their fields. For his landmark discovery, Edler is recognized as the ‚ÄúFather of Echocardiography.‚Äù},
	pages = {431--438},
	number = {4},
	journaltitle = {Texas Heart Institute Journal},
	shortjournal = {Tex Heart Inst J},
	author = {Singh, Siddharth and Goyal, Abha},
	urldate = {2020-05-08},
	date = {2007},
	pmid = {18172524},
	pmcid = {PMC2170493}
}

@article{watts_john_2009,
	title = {John Wild},
	volume = {339},
	rights = {¬© {BMJ} Publishing Group Ltd 2009},
	issn = {0959-8138, 1468-5833},
	url = {https://www.bmj.com/content/339/bmj.b4428},
	doi = {10.1136/bmj.b4428},
	abstract = {{\textless}p{\textgreater}Inventor of diagnostic ultrasound in medicine{\textless}/p{\textgreater}},
	journaltitle = {{BMJ}},
	shortjournal = {{BMJ}},
	author = {Watts, Geoff},
	urldate = {2020-05-08},
	date = {2009-10-26},
	langid = {english}
}

@book{resources_medical_2016,
	title = {Medical Imaging: Concepts, Methodologies, Tools, and Applications: Concepts, Methodologies, Tools, and Applications},
	isbn = {978-1-5225-0572-3},
	shorttitle = {Medical Imaging},
	abstract = {Medical imaging has transformed the ways in which various conditions, injuries, and diseases are identified, monitored, and treated. As various types of digital visual representations continue to advance and improve, new opportunities for their use in medical practice will likewise evolve. Medical Imaging: Concepts, Methodologies, Tools, and Applications presents a compendium of research on digital imaging technologies in a variety of healthcare settings. This multi-volume work contains practical examples of implementation, emerging trends, case studies, and technological innovations essential for using imaging technologies for making medical decisions. This comprehensive publication is an essential resource for medical practitioners, digital imaging technologists, researchers, and medical students.},
	pagetotal = {2119},
	publisher = {{IGI} Global},
	author = {Resources, Information, Management Association},
	date = {2016-07-18},
	langid = {english},
	note = {Google-Books-{ID}: {ifO}0DAAAQBAJ},
	keywords = {Medical / Allied Health Services / Imaging Technologies, Medical / Diagnostic Imaging / General, Medical / Diagnostic Imaging / Radiography}
}

@article{bradley_history_2008,
	title = {History of Medical Imaging},
	volume = {152},
	issn = {0003-049X},
	url = {https://www.jstor.org/stable/40541591},
	pages = {349--361},
	number = {3},
	journaltitle = {Proceedings of the American Philosophical Society},
	author = {Bradley, William G.},
	urldate = {2020-05-08},
	date = {2008}
}

@inproceedings{ramani_accelerated_2010,
	title = {An accelerated iterative reweighted least squares algorithm for compressed sensing {MRI}},
	doi = {10.1109/ISBI.2010.5490364},
	abstract = {Compressed sensing for {MRI} ({CS}-{MRI}) attempts to recover an object from undersampled k-space data by minimizing sparsity-promoting regularization criteria. The iterative reweighted least squares ({IRLS}) algorithm can perform the minimization task by solving iteration-dependent linear systems, recursively. However, this process can be slow as the associated linear system is often poorly conditioned for ill-posed problems. We propose a new scheme based on the matrix inversion lemma ({MIL}) to accelerate the solving process. We demonstrate numerically for {CS}-{MRI} that our method provides significant speed-up compared to linear and nonlinear conjugate gradient algorithms, thus making it a promising alternative for such applications.},
	eventtitle = {2010 {IEEE} International Symposium on Biomedical Imaging: From Nano to Macro},
	pages = {257--260},
	booktitle = {2010 {IEEE} International Symposium on Biomedical Imaging: From Nano to Macro},
	author = {Ramani, Sathish and Fessler, Jeffrey A.},
	date = {2010-04},
	note = {{ISSN}: 1945-8452},
	keywords = {Acceleration, Biological tissues, Compressed sensing, Fourier transforms, Iterative algorithms, Least squares methods, Linear systems, {MRI}, Magnetic resonance imaging, Mathematical model, Minimization methods, accelerated iterative reweighted least squares algorithm, associated linear system, biomedical {MRI}, compressed sensing, conjugate gradient methods, iterative methods, iterative reweighted least squares, least squares approximations, linear conjugate gradient algorithm, matrix inversion, matrix inversion lemma, medical image processing, nonlinear conjugate gradient, nonlinear conjugate gradient algorithm, sparsity-promoting regularization criteria, undersampling fc-space}
}

@article{chen_fast_2015,
	title = {Fast Iteratively Reweighted Least Squares Algorithms for Analysis-Based Sparsity Reconstruction},
	url = {http://arxiv.org/abs/1411.5057},
	abstract = {In this paper, we propose a novel algorithm for analysis-based sparsity reconstruction. It can solve the generalized problem by structured sparsity regularization with an orthogonal basis and total variation regularization. The proposed algorithm is based on the iterative reweighted least squares ({IRLS}) model, which is further accelerated by the preconditioned conjugate gradient method. The convergence rate of the proposed algorithm is almost the same as that of the traditional {IRLS} algorithms, that is, exponentially fast. Moreover, with the specifically devised preconditioner, the computational cost for each iteration is significantly less than that of traditional {IRLS} algorithms, which enables our approach to handle large scale problems. In addition to the fast convergence, it is straightforward to apply our method to standard sparsity, group sparsity, overlapping group sparsity and {TV} based problems. Experiments are conducted on a practical application: compressive sensing magnetic resonance imaging. Extensive results demonstrate that the proposed algorithm achieves superior performance over 14 state-of-the-art algorithms in terms of both accuracy and computational cost.},
	journaltitle = {{arXiv}:1411.5057 [cs]},
	author = {Chen, Chen and Huang, Junzhou and He, Lei and Li, Hongsheng},
	urldate = {2020-04-30},
	date = {2015-04-28},
	eprinttype = {arxiv},
	eprint = {1411.5057},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@thesis{ong_low_2018,
	title = {Low Dimensional Methods for High Dimensional Magnetic Resonance Imaging},
	abstract = {Author(s): Ong, Frank {\textbar} Advisor(s): Lustig, Michael {\textbar} Abstract: Magnetic Resonance Imaging ({MRI}) is an amazing imaging modality in many aspects. It offers one of the best imaging contrast for visualizing soft issues. It has no ionizing radiation at all. Its flexibility has also enabled many applications, including assessing blood flow, imaging brain activity via oxygenation contrast, and measuring tissue stiffness. Since {MRI} was invented, this imaging technology has saved numerous lives, and has been the frontier of biomedical and engineering research.On the other hand, imaging speed remains a main limitation of {MRI}. Inherently, {MRI} takes time to collect measurements, and often requires minutes to complete a scan. In this regard, {MRI} is quite similar to early cameras: Subjects have to be motionless for minutes to obtain an image, which is uncomfortable to patients. This often leads to motion and motion artifacts. When severe motion artifacts occur, scans have to be repeated.This dissertation aims to change that by developing techniques to reconstruct three-dimensional (3D) dynamic {MRI} from continuous acquisitions. An ideal 3D dynamic scan would be able to resolve all dynamics at a high spatiotemporal resolution. Subjects would not have to be motionless. The comprehensive information in the single scan would also greatly simplify clinical workflow. While this dissertation has not achieved this ideal scan yet, it proposes several innovations toward this goal. In particular, www.doi.org/10.6084/m9.figshare.7464485 shows a 3D rendering of a reconstruction result from this dissertation. Arbitrary slices at different orientation can be selected over time. Respiratory motion, contrast enhancements, and even slight bulk motion can be seen.The main challenge in high resolution 3D dynamic {MRI} is that the reconstruction problem is inherently underdetermined and demanding of computation and memory. To overcome these challenges, this dissertation builds on top of many fundamental methods, including non-Cartesian imaging, parallel imaging and compressed sensing. In particular, this dissertation heavily relies on the compressed sensing framework, which has three components: 1) the image of interest has a compressed signal representation. 2) {MRI} can acquire (pseudo)-randomized samples in k-space, which provides incoherent encoding of the underlying image. 3) sparsity/compressibility can be efficiently enforced in reconstruction to recover the compressed representation from the undersampled measurements.In this dissertation, I propose a multiscale low rank model that can compactly represent dynamic image sequences. The resulting representation can be applied beyond {MRI}, and is useful for other applications, such as motion separation in surveillance video. With the multiscale low rank representation, I propose a technique incorporating stochastic optimization to efficiently reconstruct 3D dynamic {MRI}. This makes it feasible to run such large-scale reconstructions on local workstations. To further speed up the reconstruction time, I propose accelerating the convergence of non-Cartesian reconstruction using a specially designed preconditioner. Finally, I leverage external undersampled datasets to further improve reconstruction quality using convolutional sparse coding.},
	type = {phdthesis},
	author = {Ong, Frank},
	date = {2018},
	keywords = {3D rendering, Cartesian closed category, Cell Respiration, Closed-circuit television, Compressed sensing, Computation, Electroencephalography, Entity Class - imaging modality, Image resolution, Imaging technology, Ionizing radiation, Magnetic Resonance Imaging, Mathematical optimization, Modality (human‚Äìcomputer interaction), Morphologic artifacts, Neural coding, Outlines (document), Preconditioner, Reconstruction conjecture, Sparse matrix, Stochastic optimization, Undersampling, Workstation, already-read}
}

@thesis{kummerle_understanding_nodate,
	title = {Understanding and Enhancing Data Recovery Algorithms. From Noise-Blind Sparse Recovery to Reweighted Methods for Low-Rank Matrix Optimization},
	type = {phdthesis},
	author = {K√ºmmerle, Christian}
}

@article{peng_reweighted_2014,
	title = {Reweighted Low-Rank Matrix Recovery and its Application in Image Restoration},
	volume = {44},
	doi = {10.1109/TCYB.2014.2307854},
	abstract = {In this paper, we propose a reweighted low-rank matrix recovery method and demonstrate its application for robust image restoration. In the literature, principal component pursuit solves low-rank matrix recovery problem via a convex program of mixed nuclear norm and l1 norm. Inspired by reweighted l1 minimization for sparsity enhancement, we propose reweighting singular values to enhance low rank of a matrix. An efficient iterative reweighting scheme is proposed for enhancing low rank and sparsity simultaneously and the performance of low-rank matrix recovery is prompted greatly. We demonstrate the utility of the proposed method both on numerical simulations and real images/videos restoration, including single image restoration, hyperspectral image restoration, and background modeling from corrupted observations. All of these experiments give empirical evidence on significant improvements of the proposed algorithm over previous work on low-rank matrix recovery.},
	pages = {2418--30},
	journaltitle = {{IEEE} transactions on cybernetics},
	shortjournal = {{IEEE} transactions on cybernetics},
	author = {Peng, Yigang and Suo, Jinli and Dai, Qionghai and Xu, Wenli},
	date = {2014-12-01}
}

@article{barnett_parallel_2018,
	title = {A parallel non-uniform fast Fourier transform library based on an "exponential of semicircle" kernel},
	url = {https://www.arxiv-vanity.com/papers/1808.06736/},
	abstract = {The nonuniform fast Fourier transform
({NUFFT}) generalizes the {FFT} to off-grid data.
Its many applications
include image reconstruction, data analysis,
and the numerical solution of differential equations.
We present {FINUFFT}, an efficient parallel library
for type 1 (nonuniform¬†to uniform), type 2 (uniform¬†to nonuniform), or
type 3 (nonuniform¬†to nonuniform) transforms, in dimensions 1, 2, or 3.
It uses minimal {RAM}, requires no precomputation or plan steps,
and has a simple interface to several languages.
We perform the expensive
spreading/interpolation between nonuniform points and the fine grid
via a simple new kernel‚Äîthe
‚Äúexponential of semicircle‚Äù
eŒ≤‚àö1‚àíx2 in x‚àà[‚àí1,1]‚Äîin a cache-aware load-balanced multithreaded implementation.
The deconvolution step requires the Fourier transform of the kernel,
for which we propose efficient numerical quadrature.
For types 1 and 2,
rigorous error bounds asymptotic in the kernel width
approach the fastest known exponential rate, namely
that of the Kaiser‚ÄìBessel kernel.
We benchmark against several popular {CPU}-based libraries,
showing favorable speed and memory footprint,
especially in three dimensions when high accuracy and/or
clustered point distributions are desired.},
	author = {Barnett, Alex H. and Magland, Jeremy F. and Klinteberg, Ludvig af},
	urldate = {2020-04-22},
	date = {2018-08-21},
	langid = {english}
}
@article{ruiz-antolin_nonuniform_2017,
	title = {A nonuniform fast Fourier transform based on low rank approximation},
	url = {http://arxiv.org/abs/1701.04492},
	abstract = {By viewing the nonuniform discrete Fourier transform ({NUDFT}) as a perturbed version of a uniform discrete Fourier transform, we propose a fast, stable, and simple algorithm for computing the {NUDFT} that costs \${\textbackslash}mathcal\{O\}(N{\textbackslash}log N{\textbackslash}log(1/{\textbackslash}epsilon)/{\textbackslash}log{\textbackslash}!{\textbackslash}log(1/{\textbackslash}epsilon))\$ operations based on the fast Fourier transform, where \$N\$ is the size of the transform and \$0{\textless}{\textbackslash}epsilon {\textless}1\$ is a working precision. Our key observation is that a {NUDFT} and {DFT} matrix divided entry-by-entry is often well-approximated by a low rank matrix, allowing us to express a {NUDFT} matrix as a sum of diagonally-scaled {DFT} matrices. Our algorithm is simple to implement, automatically adapts to any working precision, and is competitive with state-of-the-art algorithms. In the fully uniform case, our algorithm is essentially the {FFT}. We also describe quasi-optimal algorithms for the inverse {NUDFT} and two-dimensional {NUDFTs}.},
	journaltitle = {{arXiv}:1701.04492 [math]},
	author = {Ruiz-Antolin, Diego and Townsend, Alex},
	urldate = {2020-04-22},
	date = {2017-01-16},
	eprinttype = {arxiv},
	eprint = {1701.04492},
	keywords = {Mathematics - Numerical Analysis}
}

@article{schmischke_nonequispaced_2018,
	title = {Nonequispaced Fast Fourier Transform ({NFFT}) Interface for Julia},
	url = {http://arxiv.org/abs/1810.09891},
	abstract = {This report describes the newly added Julia interface to the {NFFT}3 library. We explain the multidimensional {NFFT} algorithm and basics of the interface. Furthermore, we go into detail about the different parameters and how to adjust them properly.},
	journaltitle = {{arXiv}:1810.09891 [cs]},
	author = {Schmischke, Michael},
	urldate = {2020-04-22},
	date = {2018-10-23},
	eprinttype = {arxiv},
	eprint = {1810.09891},
	keywords = {Computer Science - Mathematical Software}
}

@article{parikh_proximal_2014,
	title = {Proximal Algorithms},
	volume = {1},
	issn = {2167-3888, 2167-3918},
	url = {https://www.nowpublishers.com/article/Details/OPT-003},
	doi = {10.1561/2400000003},
	abstract = {Proximal Algorithms},
	pages = {127--239},
	number = {3},
	journaltitle = {Foundations and Trends¬Æ in Optimization},
	shortjournal = {{OPT}},
	author = {Parikh, Neal and Boyd, Stephen},
	urldate = {2020-02-28},
	date = {2014-01-13},
	keywords = {to-read}
}

@article{cai_singular_2010,
	title = {A Singular Value Thresholding Algorithm for Matrix Completion},
	volume = {20},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/080738970},
	doi = {10.1137/080738970},
	abstract = {This paper introduces a novel algorithm to approximate the matrix with minimum nuclear norm among all matrices obeying a set of convex constraints. This problem may be understood as the convex relaxation of a rank minimization problem and arises in many important applications as in the task of recovering a large matrix from a small subset of its entries (the famous Netflix problem). Off-the-shelf algorithms such as interior point methods are not directly amenable to large problems of this kind with over a million unknown entries. This paper develops a simple first-order and easy-to-implement algorithm that is extremely efficient at addressing problems in which the optimal solution has low rank. The algorithm is iterative, produces a sequence of matrices \${\textbackslash}\{{\textbackslash}boldsymbol\{X\}{\textasciicircum}k,{\textbackslash}boldsymbol\{Y\}{\textasciicircum}k{\textbackslash}\}\$, and at each step mainly performs a soft-thresholding operation on the singular values of the matrix \${\textbackslash}boldsymbol\{Y\}{\textasciicircum}k\$. There are two remarkable features making this attractive for low-rank matrix completion problems. The first is that the soft-thresholding operation is applied to a sparse matrix; the second is that the rank of the iterates \${\textbackslash}\{{\textbackslash}boldsymbol\{X\}{\textasciicircum}k{\textbackslash}\}\$ is empirically nondecreasing. Both these facts allow the algorithm to make use of very minimal storage space and keep the computational cost of each iteration low. On the theoretical side, we provide a convergence analysis showing that the sequence of iterates converges. On the practical side, we provide numerical examples in which \$1,000{\textbackslash}times1,000\$ matrices are recovered in less than a minute on a modest desktop computer. We also demonstrate that our approach is amenable to very large scale problems by recovering matrices of rank about 10 with nearly a billion unknowns from just about 0.4\% of their sampled entries. Our methods are connected with the recent literature on linearized Bregman iterations for \${\textbackslash}ell\_1\$ minimization, and we develop a framework in which one can understand these algorithms in terms of well-known Lagrange multiplier algorithms.},
	pages = {1956--1982},
	number = {4},
	journaltitle = {{SIAM} Journal on Optimization},
	shortjournal = {{SIAM} J. Optim.},
	author = {Cai, Jian-Feng. and Cand√®s, Emmanuel J. and Shen, Zuowei.},
	urldate = {2020-02-28},
	date = {2010-01-01},
	keywords = {for-reference, to-read}
}

@article{boyd_distributed_2011,
	title = {Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
	volume = {3},
	issn = {1935-8237, 1935-8245},
	url = {https://www.nowpublishers.com/article/Details/MAL-016},
	doi = {10.1561/2200000016},
	abstract = {Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
	pages = {1--122},
	number = {1},
	journaltitle = {Foundations and Trends¬Æ in Machine Learning},
	shortjournal = {{MAL}},
	author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
	urldate = {2020-02-28},
	date = {2011-07-26},
	keywords = {to-read}
}

@article{carmon_accelerated_2018,
	title = {Accelerated Methods for {NonConvex} Optimization},
	volume = {28},
	issn = {1052-6234},
	url = {https://epubs.siam.org/doi/abs/10.1137/17M1114296},
	doi = {10.1137/17M1114296},
	abstract = {We present an accelerated gradient method for nonconvex optimization problems with Lipschitz continuous first and second derivatives. In a time \$O({\textbackslash}epsilon{\textasciicircum}\{-7/4\} {\textbackslash}log(1/ {\textbackslash}epsilon) )\$, the method finds an \${\textbackslash}epsilon\$-stationary point, meaning a point \$x\$ such that \${\textbackslash}{\textbar}{\textbackslash}nabla f(x){\textbackslash}{\textbar} {\textbackslash}le {\textbackslash}epsilon\$. The method improves upon the \$O({\textbackslash}epsilon{\textasciicircum}\{-2\} )\$ complexity of gradient descent and provides the additional second-order guarantee that \${\textbackslash}lambda\_\{{\textbackslash}min\}({\textbackslash}nabla{\textasciicircum}2 f(x)) {\textbackslash}gtrsim -{\textbackslash}epsilon{\textasciicircum}\{1/2\}\$ for the computed \$x\$. Furthermore, our method is Hessian free, i.e., it only requires gradient computations, and is therefore suitable for large-scale applications.},
	pages = {1751--1772},
	number = {2},
	journaltitle = {{SIAM} Journal on Optimization},
	shortjournal = {{SIAM} J. Optim.},
	author = {Carmon, Yair. and Duchi, John C. and Hinder, Oliver. and Sidford, Aaron.},
	urldate = {2020-02-28},
	date = {2018-01-01},
	keywords = {already-read}
}

@article{kim_optimized_2016,
	title = {Optimized first-order methods for smooth convex minimization},
	volume = {159},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/s10107-015-0949-3},
	doi = {10.1007/s10107-015-0949-3},
	abstract = {We introduce new optimized first-order methods for smooth unconstrained convex minimization. Drori and Teboulle (Math Program 145(1‚Äì2):451‚Äì482, 2014. doi:10.1007/s10107-013-0653-0) recently described a numerical method for computing the N-iteration optimal step coefficients in a class of first-order algorithms that includes gradient methods, heavy-ball methods¬†(Polyak in {USSR} Comput Math Math Phys 4(5):1‚Äì17, 1964. doi:10.1016/0041-5553(64)90137-5), and Nesterov‚Äôs fast gradient methods (Nesterov in Sov Math Dokl 27(2):372‚Äì376, 1983; Math Program 103(1):127‚Äì152, 2005. doi:10.1007/s10107-004-0552-5). However, the numerical method in¬†Drori and Teboulle (2014) is computationally expensive for large N, and the corresponding numerically optimized first-order algorithm in¬†Drori and Teboulle (2014) requires impractical memory and computation for large-scale optimization problems. In this paper, we propose optimized first-order algorithms that achieve a convergence bound that is two times smaller than for Nesterov‚Äôs fast gradient methods; our bound is found analytically and refines the numerical bound in¬†Drori and Teboulle (2014). Furthermore, the proposed optimized first-order methods have efficient forms that are remarkably similar to Nesterov‚Äôs fast gradient methods.},
	pages = {81--107},
	number = {1},
	journaltitle = {Mathematical Programming},
	shortjournal = {Math. Program.},
	author = {Kim, Donghwan and Fessler, Jeffrey A.},
	urldate = {2020-02-28},
	date = {2016-09-01},
	langid = {english},
	keywords = {already-read}
}

@article{lin_efficient_2019,
	title = {Efficient Dynamic Parallel {MRI} Reconstruction for the Low-Rank Plus Sparse Model},
	volume = {5},
	issn = {2573-0436},
	doi = {10.1109/TCI.2018.2882089},
	abstract = {The low-rank plus sparse (L+S) decomposition model enables the reconstruction of undersampled dynamic parallel magnetic resonance imaging data. Solving for the low rank and the sparse components involves nonsmooth composite convex optimization, and algorithms for this problem can be categorized into proximal gradient methods and variable splitting methods. This paper investigates new efficient algorithms for both schemes. While current proximal gradient techniques for the L+S model involve the classical iterative soft thresholding algorithm ({ISTA}), this paper considers two accelerated alternatives, one based on the fast iterative shrinkage-thresholding algorithm ({FISTA}) and the other with the recent proximal optimized gradient method ({POGM}). In the augmented Lagrangian ({AL}) framework, we propose an efficient variable splitting scheme based on the form of the data acquisition operator, leading to simpler computation than the conjugate gradient approach required by existing {AL} methods. Numerical results suggest faster convergence of the efficient implementations for both frameworks, with {POGM} providing the fastest convergence overall and the practical benefit of being free of algorithm tuning parameters.},
	pages = {17--26},
	number = {1},
	journaltitle = {{IEEE} Transactions on Computational Imaging},
	author = {Lin, Claire Yilin and Fessler, Jeffrey A.},
	date = {2019-03},
	keywords = {Acceleration, Coils, Convergence, Gradient methods, Heuristic algorithms, Image reconstruction, Magnetic resonance imaging, Parallel magnetic resonance imaging ({MRI}), accelerated algorithms, algorithm tuning parameters, already-read, augmented lagrangian ({AL}), biomedical {MRI}, classical iterative soft thresholding algorithm, conjugate gradient approach, convex programming, current proximal gradient techniques, data acquisition, dynamic {MRI}, dynamic parallel {MRI} reconstruction, existing {AL} methods, gradient methods, image reconstruction, implemented, iterative methods, iterative shrinkage-thresholding algorithm, low-rank, medical image processing, nonsmooth composite convex optimization, proximal gradient method ({PGM}), proximal gradient methods, proximal optimized gradient method, sparse components, sparse decomposition model, sparse model, sparsity, undersampled dynamic parallel magnetic resonance imaging data, variable splitting}
}

@inproceedings{gueddari_self-calibrating_2018,
	title = {Self-Calibrating Nonlinear Reconstruction Algorithms for Variable Density Sampling and Parallel Reception {MRI}},
	doi = {10.1109/SAM.2018.8448776},
	abstract = {Compressed Sensing has allowed a significant reduction of acquisition times in {MRI}, especially in the high resolution (e.g., 400 Œºm) context. However, in this setting {CS} must be combined with parallel reception as multichannel coil acquisitions maintain high input signal-to-noise ratio ({SNR}). To get rid of usual parallel imaging limitations (output {SNR} loss), non-Cartesian trajectories provide a gain in sampling efficiency in the {CS} context. In this paper, we propose a self-calibrating {MRI} reconstruction framework that handles variable density sampling. Low resolution sensitivity maps are estimated from the low frequency k-space content using an original and fast method while {MR} images are reconstructed using a nonlinear iterative algorithm, which promotes sparsity in the wavelet domain. As regards the optimization task, we compare three first-order proximal gradient methods: Forward Backward ({FB}), Fast Iterative Soft Thresolding Algorithm ({FISTA}) and Proximal Optimized Gradient Method ({POGM}) and evaluate their respective convergence speed. Comparison with state-of-the-art (i.e., ‚Ñìl-{ESPIRiT}) suggests that our self-calibrating {POGM}-based algorithm outperforms current approaches both in terms of image quality and computing time on several acquired data collected at 7 Tesla and we will focus more specifically on prospective non-Cartesian 8-fold accelerated in vivo Human brain data.},
	eventtitle = {2018 {IEEE} 10th Sensor Array and Multichannel Signal Processing Workshop ({SAM})},
	pages = {415--419},
	booktitle = {2018 {IEEE} 10th Sensor Array and Multichannel Signal Processing Workshop ({SAM})},
	author = {Gueddari, Loubna El and Lazarus, C. and Carri√©, H. and Vignaud, A. and Ciuciu, Ph.},
	date = {2018-07},
	note = {{ISSN}: 2151-870X},
	keywords = {Acceleration, {CS} context, Compressed Sensing, Fast Iterative Soft Thresolding Algorithm, Image reconstruction, Image resolution, {MR} images, Magnetic resonance imaging, Prospective compressed sensing, Proximal Optimized Gradient Method, Sensitivity, Signal processing algorithms, acquisition times, already-read, biomedical {MRI}, brain, calibration, compressed sensing, computing time, convergence of numerical methods, convergence speed, first-order proximal gradient methods, forward backward method, gradient methods, high input signal-to-noise ratio, high resolution context, image quality, image reconstruction, image resolution, image sampling, in vivo human brain data, iterative methods, low frequency k-space content, low resolution sensitivity maps, magnetic flux density 7 tesla, medical image processing, multichannel coil acquisitions, non-Cartesian trajectories, {nonCartesian} 8-fold, {nonCartesian} trajectory, nonlinear iterative algorithm, nonlinear reconstruction, optimisation, optimization task, output {SNR} loss, parallel reception, parallel reception {MRI}, sampling efficiency, self-calibrating {MRI} reconstruction framework, self-calibrating {POGM}-based algorithm, self-calibrating nonlinear reconstruction algorithms, variable density sampling, wavelet domain, wavelet transforms}
}

@article{fessler_optimization_2019,
	title = {Optimization methods for {MR} image reconstruction (long version)},
	url = {http://arxiv.org/abs/1903.03510},
	abstract = {The development of compressed sensing methods for magnetic resonance ({MR}) image reconstruction led to an explosion of research on models and optimization algorithms for {MR} imaging ({MRI}). Roughly 10 years after such methods first appeared in the {MRI} literature, the U.S. Food and Drug Administration ({FDA}) approved certain compressed sensing methods for commercial use, making compressed sensing a clinical success story for {MRI}. This review paper summarizes several key models and optimization algorithms for {MR} image reconstruction, including both the type of methods that have {FDA} approval for clinical use, as well as more recent methods being considered in the research community that use data-adaptive regularizers. Many algorithms have been devised that exploit the structure of the system model and regularizers used in {MRI}; this paper strives to collect such algorithms in a single survey. Many of the ideas used in optimization methods for {MRI} are also useful for solving other inverse problems.},
	journaltitle = {{arXiv}:1903.03510 [eess, math]},
	author = {Fessler, Jeffrey A.},
	urldate = {2020-02-28},
	date = {2019-06-13},
	eprinttype = {arxiv},
	eprint = {1903.03510},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Mathematics - Optimization and Control, already-read, implemented}
}

@article{lustig_sparse_2007,
	title = {Sparse {MRI}: The application of compressed sensing for rapid {MR} imaging},
	volume = {58},
	rights = {Copyright ¬© 2007 Wiley‚ÄêLiss, Inc.},
	issn = {1522-2594},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.21391},
	doi = {10.1002/mrm.21391},
	shorttitle = {Sparse {MRI}},
	abstract = {The sparsity which is implicit in {MR} images is exploited to significantly undersample k-space. Some {MR} images such as angiograms are already sparse in the pixel representation; other, more complicated images have a sparse representation in some transform domain‚Äìfor example, in terms of spatial finite-differences or their wavelet coefficients. According to the recently developed mathematical theory of compressed-sensing, images with a sparse representation can be recovered from randomly undersampled k-space data, provided an appropriate nonlinear recovery scheme is used. Intuitively, artifacts due to random undersampling add as noise-like interference. In the sparse transform domain the significant coefficients stand out above the interference. A nonlinear thresholding scheme can recover the sparse coefficients, effectively recovering the image itself. In this article, practical incoherent undersampling schemes are developed and analyzed by means of their aliasing interference. Incoherence is introduced by pseudo-random variable-density undersampling of phase-encodes. The reconstruction is performed by minimizing the ‚Ñì1 norm of a transformed image, subject to data fidelity constraints. Examples demonstrate improved spatial resolution and accelerated acquisition for multislice fast spin-echo brain imaging and 3D contrast enhanced angiography. Magn Reson Med, 2007. ¬© 2007 Wiley-Liss, Inc.},
	pages = {1182--1195},
	number = {6},
	journaltitle = {Magnetic Resonance in Medicine},
	author = {Lustig, Michael and Donoho, David and Pauly, John M.},
	urldate = {2020-02-28},
	date = {2007},
	langid = {english},
	keywords = {already-read, compressed sensing, compressive sampling, implemented, nonlinear reconstruction, random sampling, rapid {MRI}, sparse reconstruction, sparsity}
}

@article{lustig_compressed_2008,
	title = {Compressed Sensing {MRI}},
	volume = {25},
	issn = {1558-0792},
	doi = {10.1109/MSP.2007.914728},
	abstract = {This article reviews the requirements for successful compressed sensing ({CS}), describes their natural fit to {MRI}, and gives examples of four interesting applications of {CS} in {MRI}. The authors emphasize on an intuitive understanding of {CS} by describing the {CS} reconstruction as a process of interference cancellation. There is also an emphasis on the understanding of the driving factors in applications, including limitations imposed by {MRI} hardware, by the characteristics of different types of images, and by clinical concerns.},
	pages = {72--82},
	number = {2},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {Lustig, Michael and Donoho, David L. and Santos, Juan M. and Pauly, John M.},
	date = {2008-03},
	keywords = {Biomedical imaging, Compressed sensing, Encoding, Image coding, Image reconstruction, {MRI}, Magnetic resonance imaging, Magnetization, Protons, Radio frequency, Wavelet transforms, already-read, biomedical {MRI}, compressed sensing, image reconstruction, interference cancellation, magnetic resonance imaging, medical image processing, review, reviews}
}

@article{ong_beyond_2016,
	title = {Beyond Low Rank + Sparse: Multi-scale Low Rank Matrix Decomposition},
	volume = {10},
	issn = {1932-4553, 1941-0484},
	url = {http://arxiv.org/abs/1507.08751},
	doi = {10.1109/JSTSP.2016.2545518},
	shorttitle = {Beyond Low Rank + Sparse},
	abstract = {We present a natural generalization of the recent low rank + sparse matrix decomposition and consider the decomposition of matrices into components of multiple scales. Such decomposition is well motivated in practice as data matrices often exhibit local correlations in multiple scales. Concretely, we propose a multi-scale low rank modeling that represents a data matrix as a sum of block-wise low rank matrices with increasing scales of block sizes. We then consider the inverse problem of decomposing the data matrix into its multi-scale low rank components and approach the problem via a convex formulation. Theoretically, we show that under various incoherence conditions, the convex program recovers the multi-scale low rank components {\textbackslash}revised\{either exactly or approximately\}. Practically, we provide guidance on selecting the regularization parameters and incorporate cycle spinning to reduce blocking artifacts. Experimentally, we show that the multi-scale low rank decomposition provides a more intuitive decomposition than conventional low rank methods and demonstrate its effectiveness in four applications, including illumination normalization for face images, motion separation for surveillance videos, multi-scale modeling of the dynamic contrast enhanced magnetic resonance imaging and collaborative filtering exploiting age information.},
	pages = {672--687},
	number = {4},
	journaltitle = {{IEEE} Journal of Selected Topics in Signal Processing},
	shortjournal = {{IEEE} J. Sel. Top. Signal Process.},
	author = {Ong, Frank and Lustig, Michael},
	urldate = {2020-01-27},
	date = {2016-06},
	eprinttype = {arxiv},
	eprint = {1507.08751},
	keywords = {Computer Science - Information Theory, Electrical Engineering and Systems Science - Systems and Control, Mathematics - Numerical Analysis, Mathematics - Optimization and Control, already-read, implemented}
}

@article{wissmann_mrxcat_2014,
	title = {{MRXCAT}: Realistic numerical phantoms for cardiovascular magnetic resonance},
	volume = {16},
	issn = {1532-429X},
	url = {https://doi.org/10.1186/s12968-014-0063-3},
	doi = {10.1186/s12968-014-0063-3},
	shorttitle = {{MRXCAT}},
	abstract = {Computer simulations are important for validating novel image acquisition and reconstruction strategies. In cardiovascular magnetic resonance ({CMR}), numerical simulations need to combine anatomical information and the effects of cardiac and/or respiratory motion. To this end, a framework for realistic {CMR} simulations is proposed and its use for image reconstruction from undersampled data is demonstrated.},
	pages = {63},
	number = {1},
	journaltitle = {Journal of Cardiovascular Magnetic Resonance},
	shortjournal = {Journal of Cardiovascular Magnetic Resonance},
	author = {Wissmann, Lukas and Santelli, Claudio and Segars, William P. and Kozerke, Sebastian},
	urldate = {2020-01-28},
	date = {2014-08-20},
	keywords = {for-reference}
}

@article{zibulevsky_l1-l2_2010,
	title = {L1-L2 Optimization in Signal and Image Processing},
	volume = {27},
	issn = {1053-5888},
	url = {http://ieeexplore.ieee.org/document/5447114/},
	doi = {10.1109/MSP.2010.936023},
	pages = {76--88},
	number = {3},
	journaltitle = {{IEEE} Signal Processing Magazine},
	shortjournal = {{IEEE} Signal Process. Mag.},
	author = {Zibulevsky, Michael and Elad, Michael},
	urldate = {2020-01-24},
	date = {2010-05},
	keywords = {2019-12-meeting, to-read}
}

@article{pielawski_introducing_2019,
	title = {Introducing Hann windows for reducing edge-effects in patch-based image segmentation},
	url = {http://arxiv.org/abs/1910.07831},
	abstract = {There is a limitation in the size of an image that can be processed using computationally demanding methods such as e.g. Convolutional Neural Networks ({CNNs}). Some imaging modalities - notably biological and medical - can result in images up to a few gigapixels in size, meaning that they have to be divided into smaller parts, or patches, for processing. However, when performing image segmentation, this may lead to undesirable artefacts, such as edge effects in the final re-combined image. We introduce windowing methods from signal processing to effectively reduce such edge effects. With the assumption that the central part of an image patch often holds richer contextual information than its sides and corners, we reconstruct the prediction by overlapping patches that are being weighted depending on 2-dimensional windows. We compare the results of four different windows: Hann, Bartlett-Hann, Triangular and a recently proposed window by Cui et al., and show that the cosine-based Hann window achieves the best improvement as measured by the Structural Similarity Index ({SSIM}). The proposed windowing method can be used together with any {CNN} model for segmentation without any modification and significantly improves network predictions.},
	journaltitle = {{arXiv}:1910.07831 [cs, eess]},
	author = {Pielawski, Nicolas and W√§hlby, Carolina},
	urldate = {2020-02-12},
	date = {2019-10-17},
	eprinttype = {arxiv},
	eprint = {1910.07831},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, for-reference}
}

@article{kummerle_denoising_2018,
	title = {Denoising and Completion of Structured Low-Rank Matrices via Iteratively Reweighted Least Squares},
	url = {http://arxiv.org/abs/1811.07472},
	abstract = {We propose a new Iteratively Reweighted Least Squares ({IRLS}) algorithm for the problem of completing or denoising low-rank matrices that are structured, e.g., that possess a Hankel, Toeplitz or block-Hankel/Toeplitz structure. The algorithm optimizes an objective based on a non-convex surrogate of the rank by solving a sequence of quadratic problems. Our strategy combines computational efficiency, as it operates on a lower dimensional generator space of the structured matrices, with high statistical accuracy which can be observed in experiments on hard estimation and completion tasks. Our experiments show that the proposed algorithm {StrucHMIRLS} exhibits an empirical recovery probability close to 1 from fewer samples than the state-of-the-art in a Hankel matrix completion task arising from the problem of spectral super-resolution of badly separated frequencies. Furthermore, we explain how the proposed algorithm for structured low-rank recovery can be used as preprocessing step for improved robustness in frequency or line spectrum estimation problems.},
	journaltitle = {{arXiv}:1811.07472 [cs, math]},
	author = {K√ºmmerle, Christian and Verdun, Claudio Mayrink},
	urldate = {2020-02-27},
	date = {2018-11-18},
	eprinttype = {arxiv},
	eprint = {1811.07472},
	keywords = {Computer Science - Information Theory, {IRLS}, Mathematics - Optimization and Control, to-read}
}

@article{adams_iterative_2020,
	title = {An Iterative Method for Structured Matrix Completion},
	url = {http://arxiv.org/abs/2002.02041},
	abstract = {The task of filling-in or predicting missing entries of a matrix, from a subset of known entries, is known as \${\textbackslash}textit\{matrix completion\}\$. In today's data-driven world, data completion is essential whether it is the main goal or a pre-processing step. In recent work, a modification to the standard nuclear norm minimization for matrix completion has been made to take into account \${\textbackslash}textit\{structural differences\}\$ between observed and unobserved entries. One example of such structural difference is when the probability that an entry is observed or not depends mainly on the value of the entry. We propose adjusting an Iteratively Reweighted Least Squares ({IRLS}) algorithm for low-rank matrix completion to take into account \${\textbackslash}textit\{sparsity-based\}\$ structure in the missing entries. We also present an iterative gradient-projection-based implementation of the algorithm, and present numerical experiments showing that the proposed method often outperforms the {IRLS} algorithm in structured settings.},
	journaltitle = {{arXiv}:2002.02041 [cs, math]},
	author = {Adams, Henry and Kassab, Lara and Needell, Deanna},
	urldate = {2020-02-27},
	date = {2020-02-05},
	eprinttype = {arxiv},
	eprint = {2002.02041},
	keywords = {{IRLS}, Mathematics - Numerical Analysis, to-read}
}

@article{levine_3d_2017,
	title = {3D Cartesian {MRI} with compressed sensing and variable view sharing using complementary poisson-disc sampling: 3D Cartesian {MRI} with Compressed Sensing and Variable View Sharing},
	volume = {77},
	issn = {07403194},
	url = {http://doi.wiley.com/10.1002/mrm.26254},
	doi = {10.1002/mrm.26254},
	shorttitle = {3D Cartesian {MRI} with compressed sensing and variable view sharing using complementary poisson-disc sampling},
	pages = {1774--1785},
	number = {5},
	journaltitle = {Magnetic Resonance in Medicine},
	shortjournal = {Magn. Reson. Med.},
	author = {Levine, Evan and Daniel, Bruce and Vasanawala, Shreyas and Hargreaves, Brian and Saranathan, Manojkumar},
	urldate = {2020-02-03},
	date = {2017-05},
	langid = {english}
}

@article{saranathan_differential_2012,
	title = {{DIfferential} subsampling with cartesian ordering ({DISCO}): A high spatio-temporal resolution dixon imaging sequence for multiphasic contrast enhanced abdominal imaging},
	volume = {35},
	issn = {1522-2586},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.23602},
	doi = {10.1002/jmri.23602},
	shorttitle = {{DIfferential} subsampling with cartesian ordering ({DISCO})},
	abstract = {Purpose: To develop and evaluate a multiphasic contrast-enhanced {MRI} method called {DIfferential} Sub-sampling with Cartesian Ordering ({DISCO}) for abdominal imaging. Materials and Methods: A three-dimensional, variable density pseudo-random k-space segmentation scheme was developed and combined with a Dixon-based fat-water separation algorithm to generate high temporal resolution images with robust fat suppression and without compromise in spatial resolution or coverage. With institutional review board approval and informed consent, 11 consecutive patients referred for abdominal {MRI} at 3 Tesla (T) were imaged with both {DISCO} and a routine clinical three-dimensional {SPGR}-Dixon ({LAVA} {FLEX}) sequence. All images were graded by two radiologists using quality of fat suppression, severity of artifacts, and overall image quality as scoring criteria. For assessment of arterial phase capture efficiency, the number of temporal phases with angiographic phase and hepatic arterial phase was recorded. Results: There were no significant differences in quality of fat suppression, artifact severity or overall image quality between {DISCO} and {LAVA} {FLEX} images (P {\textgreater} 0.05, Wilcoxon signed rank test). The angiographic and arterial phases were captured in all 11 patients scanned using the {DISCO} acquisition (mean number of phases were two and three, respectively). Conclusion: {DISCO} effectively captures the fast dynamics of abdominal pathology such as hyperenhancing hepatic lesions with a high spatio-temporal resolution. Typically, 1.1 √ó 1.5 √ó 3 mm spatial resolution over 60 slices was achieved with a temporal resolution of 4‚Äì5 s. J. Magn. Reson. Imaging 2012;35:1484‚Äì1492. ¬© 2012 Wiley Periodicals, Inc.},
	pages = {1484--1492},
	number = {6},
	journaltitle = {Journal of Magnetic Resonance Imaging},
	author = {Saranathan, Manojkumar and Rettmann, Dan W. and Hargreaves, Brian A. and Clarke, Sharon E. and Vasanawala, Shreyas S.},
	urldate = {2020-02-03},
	date = {2012},
	langid = {english},
	keywords = {Dixon fat-water separation, dynamic contrast enhanced {MRI}, time resolved imaging, tumor imaging}
}

@online{noauthor_rider_nodate,
	title = {Rider Neuro {MRI}},
	url = {https://wiki.cancerimagingarchive.net/display/Public/RIDER+NEURO+MRI},
	abstract = {{DCE}‚Äê{MRI}:  All 19 patients had repeat dynamic contrast‚Äêenhanced {MRI} ({DCE}‚Äê{MRI}) datasets on the same 1.5T imaging magnet.  On the basis of T2‚Äêweighted images, technologists chose 16 image locations using 5mm thick contiguous slices for the imaging.  For T1 mapping, multi‚Äêflip 3D {FLASH} images were obtained using flip angles of 5, 10, 15, 20, 25 and 30 degrees, {TR} of 4.43 ms, {TE} of 2.1 ms, 2 signal averages.  Dynamic images were obtained during the intravenous injection of 0.1mmol/kg of Magnevist intravenous at 3ccs/second, started 24 seconds after the scan had begun.  The dynamic images were acquired using a 3D {FLASH} technique, using a flip angle of 25 degrees, {TR} of 3.8 ms, {TE} of 1.8 ms using a 1 x1 x 5mm voxel size.  The 16 slice imaging set was obtained every 4.8 sec.}
}

@online{noauthor_respiratory_nodate,
	title = {Respiratory Organ Motion from 4DMRI},
	url = {http://www.vision.ee.ethz.ch/~organmot/chapter_download.shtml},
	urldate = {2020-01-31}
}

@article{lemarechal_cauchy_2012,
	title = {Cauchy and the Gradient Method},
	pages = {4},
	journaltitle = {Documenta Mathematica},
	author = {Lemarechal, Claude},
	date = {2012},
	langid = {english}
}